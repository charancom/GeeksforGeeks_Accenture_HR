{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:27:29.818117Z",
     "start_time": "2025-04-11T13:27:29.788949Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e219fcee18bb145d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:27:33.021403Z",
     "start_time": "2025-04-11T13:27:29.856179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from googleapiclient.discovery import build\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive.readonly']\n",
    "SERVICE_ACCOUNT_FILE = 'C:\\\\Users\\sreec\\PycharmProjects\\ENTERPRISE_RAG\\gen-lang-client-0166514082-32b8ddccac3a.json'\n",
    "\n",
    "SERVICE_ACCOUNT_FILE = 'C:\\\\Users\\\\sreec\\\\PycharmProjects\\\\ENTERPRISE_RAG\\\\gen-lang-client-0166514082-32b8ddccac3a.json'\n",
    "\n",
    "creds = service_account.Credentials.from_service_account_file(\n",
    "    SERVICE_ACCOUNT_FILE, scopes=SCOPES\n",
    ")\n",
    "drive_service = build('drive', 'v3', credentials=creds)\n",
    "folder_id = '1JfFPowlXj4dQIZCl7H_rI8XlmrsjDCjqJbT8-F-pQNIQutQsMv3m2YNPxHW6XNlaZF9VmzKK'\n",
    "query = f\"'{folder_id}' in parents\"\n",
    "results = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
    "files = results.get('files', [])\n",
    "if not files:\n",
    "    print('No files found in the folder.')\n",
    "else:\n",
    "    print(f\"Found {len(files)} file(s) in the folder:\")\n",
    "    for file in files:\n",
    "        print(f\"{file['name']} (ID: {file['id']})\")"
   ],
   "id": "79553c4ef84b46c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 file(s) in the folder:\n",
      "Rithul_Rakesh.pdf (ID: 1huTInCSx2czjeoTzFYccB328nZpGdrFm)\n",
      "Raghav Balakrishnan_PES University.pdf (ID: 1FthTjAvhCT-irqmdo85HZTMsRW4GrxQO)\n",
      "nitheesh_resume.pdf (ID: 1f6R3U8Gn4A9bpgaooXDKdd3S2bCzuB-q)\n",
      "NEVILLE_JOSEPH.pdf (ID: 1irDGX6ULMyU3qS6OqE7LSJallnzUuNw2)\n",
      "Sreecharan_pes_updated (3).pdf (ID: 1JFi9nQ88MA2pMLv1OQ3mtnIpCGmqgl4C)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:27:44.436782Z",
     "start_time": "2025-04-11T13:27:33.024914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from googleapiclient.discovery import build\n",
    "from google.oauth2 import service_account\n",
    "import os\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "\n",
    "# Define the output directory\n",
    "output_directory_path = \"C:\\\\Users\\sreec\\PycharmProjects\\ENTERPRISE_RAG\\GENAI_PROJECT\\GoogleDriveFiles\"  # Change this path as needed\n",
    "# Ensure the directory exists\n",
    "os.makedirs(output_directory_path, exist_ok=True)\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "\n",
    "creds = service_account.Credentials.from_service_account_file(\n",
    "    SERVICE_ACCOUNT_FILE, scopes=SCOPES\n",
    ")\n",
    "drive_service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "folder_id = '1JfFPowlXj4dQIZCl7H_rI8XlmrsjDCjqJbT8-F-pQNIQutQsMv3m2YNPxHW6XNlaZF9VmzKK'\n",
    "query = f\"'{folder_id}' in parents and trashed=false\"\n",
    "results = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
    "files = results.get('files', [])\n",
    "\n",
    "if not files:\n",
    "    print('No files found in the folder.')\n",
    "else:\n",
    "    print(f\"Found {len(files)} file(s) in the folder:\")    \n",
    "    for file in files:\n",
    "        file_id = file['id']\n",
    "        file_name = file['name']\n",
    "        \n",
    "        print(f\"Downloading: {file_name} (ID: {file_id})\")\n",
    "\n",
    "        # Request to download file\n",
    "        request = drive_service.files().get_media(fileId=file_id)\n",
    "        file_path = os.path.join(output_directory_path, file_name)  # Save in the specified directory\n",
    "\n",
    "        # Download the file\n",
    "        with open(file_path, 'wb') as f:\n",
    "            downloader = MediaIoBaseDownload(f, request)\n",
    "            done = False\n",
    "            while not done:\n",
    "                status, done = downloader.next_chunk()\n",
    "                print(f\"Download {int(status.progress() * 100)}% complete\")\n",
    "\n",
    "        print(f\"File downloaded: {file_path}\")"
   ],
   "id": "b4f0e8e5167c8bf4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 file(s) in the folder:\n",
      "Downloading: Rithul_Rakesh.pdf (ID: 1huTInCSx2czjeoTzFYccB328nZpGdrFm)\n",
      "Download 100% complete\n",
      "File downloaded: C:\\Users\\sreec\\PycharmProjects\\ENTERPRISE_RAG\\GENAI_PROJECT\\GoogleDriveFiles\\Rithul_Rakesh.pdf\n",
      "Downloading: Raghav Balakrishnan_PES University.pdf (ID: 1FthTjAvhCT-irqmdo85HZTMsRW4GrxQO)\n",
      "Download 100% complete\n",
      "File downloaded: C:\\Users\\sreec\\PycharmProjects\\ENTERPRISE_RAG\\GENAI_PROJECT\\GoogleDriveFiles\\Raghav Balakrishnan_PES University.pdf\n",
      "Downloading: nitheesh_resume.pdf (ID: 1f6R3U8Gn4A9bpgaooXDKdd3S2bCzuB-q)\n",
      "Download 100% complete\n",
      "File downloaded: C:\\Users\\sreec\\PycharmProjects\\ENTERPRISE_RAG\\GENAI_PROJECT\\GoogleDriveFiles\\nitheesh_resume.pdf\n",
      "Downloading: NEVILLE_JOSEPH.pdf (ID: 1irDGX6ULMyU3qS6OqE7LSJallnzUuNw2)\n",
      "Download 100% complete\n",
      "File downloaded: C:\\Users\\sreec\\PycharmProjects\\ENTERPRISE_RAG\\GENAI_PROJECT\\GoogleDriveFiles\\NEVILLE_JOSEPH.pdf\n",
      "Downloading: Sreecharan_pes_updated (3).pdf (ID: 1JFi9nQ88MA2pMLv1OQ3mtnIpCGmqgl4C)\n",
      "Download 100% complete\n",
      "File downloaded: C:\\Users\\sreec\\PycharmProjects\\ENTERPRISE_RAG\\GENAI_PROJECT\\GoogleDriveFiles\\Sreecharan_pes_updated (3).pdf\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:27:44.452309Z",
     "start_time": "2025-04-11T13:27:44.440780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ],
   "id": "ff20b67f88585e9c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "42180be6e303cc15"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:27:54.774878Z",
     "start_time": "2025-04-11T13:27:44.460845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\sreec\\PycharmProjects\\ENTERPRISE_RAG\")\n",
    "from Path_Of_GoogleDriveFiles import get_list_paths\n",
    "output_directory_list = get_list_paths(output_directory_path)\n",
    "output_directory_list"
   ],
   "id": "9d2640306fc8c7fe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\sreec\\\\PycharmProjects\\\\ENTERPRISE_RAG\\\\GENAI_PROJECT\\\\GoogleDriveFiles\\\\NEVILLE_JOSEPH.pdf',\n",
       " 'C:\\\\Users\\\\sreec\\\\PycharmProjects\\\\ENTERPRISE_RAG\\\\GENAI_PROJECT\\\\GoogleDriveFiles\\\\nitheesh_resume.pdf',\n",
       " 'C:\\\\Users\\\\sreec\\\\PycharmProjects\\\\ENTERPRISE_RAG\\\\GENAI_PROJECT\\\\GoogleDriveFiles\\\\Raghav Balakrishnan_PES University.pdf',\n",
       " 'C:\\\\Users\\\\sreec\\\\PycharmProjects\\\\ENTERPRISE_RAG\\\\GENAI_PROJECT\\\\GoogleDriveFiles\\\\Rithul_Rakesh.pdf',\n",
       " 'C:\\\\Users\\\\sreec\\\\PycharmProjects\\\\ENTERPRISE_RAG\\\\GENAI_PROJECT\\\\GoogleDriveFiles\\\\Sreecharan_pes_updated (3).pdf']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:27:54.806060Z",
     "start_time": "2025-04-11T13:27:54.783747Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "65f42257d1d95b56",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:27:55.354669Z",
     "start_time": "2025-04-11T13:27:55.015810Z"
    }
   },
   "cell_type": "code",
   "source": "storage_text = {}",
   "id": "35f6107ec8ddae68",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:28:02.119671Z",
     "start_time": "2025-04-11T13:27:55.378730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"deepseek-r1-distill-llama-70b\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ],
   "id": "6f994f3cb588ba87",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:28:02.151209Z",
     "start_time": "2025-04-11T13:28:02.123688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an assistant that normalizes the given JSON input into the following structured format:\n",
    "            and do not randomly insert \n",
    "            {{\n",
    "              \"contact_information\": {{\n",
    "                \"name\": \"<Full Name>\",\n",
    "                \"contact\": {{\n",
    "                  \"phone\": \"<Phone Number>\",\n",
    "                  \"email\": \"<Email Address>\",\n",
    "                  \"github\": \"<GitHub Profile URL>\",\n",
    "                  \"linkedin\": \"<LinkedIn Profile URL>\",\n",
    "                  \"website\": \"<Personal Website or Portfolio URL>\"\n",
    "                }}\n",
    "              }},\n",
    "              \"education\": [\n",
    "                {{\n",
    "                  \"institution\": \"<University or College Name>\",\n",
    "                  \"degree\": \"<Degree Name>\",\n",
    "                  \"field_of_study\": \"<Field of Study>\",\n",
    "                  \"duration\": \"<Start Year - End Year or Present>\",\n",
    "                  \"location\": \"<City, Country>\",\n",
    "                  \"GPA\"\n",
    "                }}\n",
    "              ],\n",
    "              \"experience\": [\n",
    "                {{\n",
    "                  \"company\": \"<Company Name>\",\n",
    "                  \"position\": \"<Job Title>\",\n",
    "                  \"duration\": \"<Start Date - End Date or Present>\",\n",
    "                  \"location\": \"<City, Country>\",\n",
    "                  \"responsibilities\": [\n",
    "                    \"<Responsibility or achievement 1>\",\n",
    "                    \"<Responsibility or achievement 2>\",\n",
    "                    \"<Responsibility or achievement 3>\"\n",
    "                  ]\n",
    "                }}\n",
    "              ],\n",
    "              \"technical_skills\": {{\n",
    "                \"languages\": [\"<Programming Language 1>\", \"<Programming Language 2>\", \"...\"],\n",
    "                \"technologies\": [\"<Technology 1>\", \"<Technology 2>\", \"...\"]\n",
    "              }},\n",
    "              \"projects\": [\n",
    "                {{\n",
    "                  \"name\": \"<Project Name>\",\n",
    "                  \"description\": \"<Brief description of the project highlighting its functionality and purpose>\"\n",
    "                }}\n",
    "              ],\n",
    "              \"courses_taught\": [\n",
    "                {{\n",
    "                  \"title\": \"<Course Name>\",\n",
    "                  \"duration\": \"<Start Date - End Date>\",\n",
    "                  \"description\": \"<Brief description of the course and topics covered>\"\n",
    "                }}\n",
    "              ],\n",
    "              \"clubs_and_community\": [\n",
    "                {{\n",
    "                  \"name\": \"<Club or Organization Name>\",\n",
    "                  \"role\": \"<Role in the Organization>\",\n",
    "                  \"description\": \"<Contributions and activities>\"\n",
    "                }}\n",
    "              ],\n",
    "              \"achievements\": [\n",
    "                {{\n",
    "                  \"event\": \"<Event or Competition Name>\",\n",
    "                  \"placement\": \"<Rank or Award>\",\n",
    "                  \"description\": \"<Brief details on the competition and accomplishment>\"\n",
    "                }}\n",
    "              ],\n",
    "              \"publications\": [\n",
    "              {{\n",
    "                \"title\": \"<Publication Title>\",\n",
    "                \"authors\": [\"<Author 1>\", \"<Author 2>\", \"...\"],\n",
    "                \"journal_or_conference\": \"<Journal or Conference Name>\",\n",
    "                \"year\": \"<Year of Publication>\",\n",
    "                \"doi\": \"<DOI or URL>\",\n",
    "                \"abstract\": \"<Brief summary of the publication>\"\n",
    "              }}\n",
    "              ]\n",
    "            }}\n",
    "            and just output the json, not anything else strictly, and follow the format mentioned strictly\"\"\"\n",
    "        ),\n",
    "        (\"human\", \"{question}\")  # Correct placeholder syntax\n",
    "    ]\n",
    ")"
   ],
   "id": "3bf3e0ff790b2278",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:28:02.166757Z",
     "start_time": "2025-04-11T13:28:02.155213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import json\n",
    "# import re\n",
    "# from llama_parse import LlamaParse\n",
    "# from langchain.chains import LLMChain\n",
    "# \n",
    "# def get_education_profile(file_path, llm, prompt):\n",
    "#     \"\"\"\n",
    "#     Parses a resume file into a structured JSON format using LlamaParse and a language model.\n",
    "# \n",
    "#     Args:\n",
    "#         file_path (str): Path to the resume file.\n",
    "#         llm: Initialized language model.\n",
    "#         prompt: Initialized prompt template.\n",
    "# \n",
    "#     Returns:\n",
    "#         tuple: (parsed_json_data, raw_text) or (None, raw_text) if parsing fails.\n",
    "#     \"\"\"\n",
    "#     # Initialize the chain\n",
    "#     chain = llm | prompt\n",
    "# \n",
    "#     # Parse the file with LlamaParse\n",
    "#     try:\n",
    "#         parsed_data = LlamaParse(result_type=\"markdown\").load_data(file_path)\n",
    "#         raw_text = parsed_data[0].text if parsed_data else \"\"\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error parsing file {file_path} with LlamaParse: {e}\")\n",
    "#         return None, None\n",
    "# \n",
    "#     if not raw_text:\n",
    "#         print(f\"Error: No data extracted from the file {file_path}.\")\n",
    "#         return None, None\n",
    "# \n",
    "#     # Prepare input for the LLM chain\n",
    "#     input_data = {\"input\": raw_text}\n",
    "# \n",
    "#     try:\n",
    "#         # Invoke the LLM chain to normalize the JSON\n",
    "#         response = chain.invoke(input_data)\n",
    "#         response_content = response.get(\"text\", \"\") if isinstance(response, dict) else response\n",
    "# \n",
    "#         # Extract JSON content from the response\n",
    "#         match = re.search(r'```json\\n(.*?)\\n```', response_content, re.DOTALL)\n",
    "#         cleaned_json_string = match.group(1).strip() if match else response_content.strip()\n",
    "# \n",
    "#         if not cleaned_json_string:\n",
    "#             print(f\"Error: Received empty JSON response for file {file_path}.\")\n",
    "#             return None, raw_text\n",
    "# \n",
    "#         # Normalize JSON keys by replacing escaped underscores\n",
    "#         cleaned_json_string = cleaned_json_string.replace(\"\\\\_\", \"_\")\n",
    "# \n",
    "#         # Parse the cleaned JSON string\n",
    "#         json_data = json.loads(cleaned_json_string)\n",
    "#         return json_data, raw_text\n",
    "# \n",
    "#     except json.JSONDecodeError as e:\n",
    "#         print(f\"Error Parsing JSON for file {file_path}: {e}\")\n",
    "#         print(\"Raw JSON String:\", cleaned_json_string)  # Debugging\n",
    "#         return None, raw_text\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing file {file_path}: {e}\")\n",
    "#         return None, raw_text"
   ],
   "id": "17f2978a62599421",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:28:02.197555Z",
     "start_time": "2025-04-11T13:28:02.175921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import re\n",
    "from llama_parse import LlamaParse\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def get_education_profile(file_path):\n",
    "    parsing_instruction = \"\"\"\n",
    "    Parse Me this Resume in the form of a json and follow the given format strictly\n",
    "                {{\n",
    "              \"contact_information\": {{\n",
    "                \"name\": \"<Full Name>\",\n",
    "                \"contact\": {{\n",
    "                  \"phone\": \"<Phone Number>\",\n",
    "                  \"email\": \"<Email Address>\",\n",
    "                  \"github\": \"<GitHub Profile URL>\",\n",
    "                  \"linkedin\": \"<LinkedIn Profile URL>\",\n",
    "                  \"website\": \"<Personal Website or Portfolio URL>\"\n",
    "                }}\n",
    "              }},\n",
    "              \"education\": [\n",
    "                {{\n",
    "                  \"institution\": \"<University or College Name>\",\n",
    "                  \"degree\": \"<Degree Name>\",\n",
    "                  \"field_of_study\": \"<Field of Study>\",\n",
    "                  \"duration\": \"<Start Year - End Year or Present>\",\n",
    "                  \"location\": \"<City, Country>\"\n",
    "                }}\n",
    "              ],\n",
    "              \"experience\": [\n",
    "                {{\n",
    "                  \"company\": \"<Company Name>\",\n",
    "                  \"position\": \"<Job Title>\",\n",
    "                  \"duration\": \"<Start Date - End Date or Present>\",\n",
    "                  \"location\": \"<City, Country>\",\n",
    "                  \"responsibilities\": [\n",
    "                    \"<Responsibility or achievement 1>\",\n",
    "                    \"<Responsibility or achievement 2>\",\n",
    "                    \"<Responsibility or achievement 3>\"\n",
    "                  ]\n",
    "                }}\n",
    "              ],\n",
    "              \"technical_skills\": {{\n",
    "                \"languages\": [\"<Programming Language 1>\", \"<Programming Language 2>\", \"...\"],\n",
    "                \"technologies\": [\"<Technology 1>\", \"<Technology 2>\", \"...\"]\n",
    "              }},\n",
    "              \"projects\": [\n",
    "                {{\n",
    "                  \"name\": \"<Project Name>\",\n",
    "                  \"description\": \"<Brief description of the project highlighting its functionality and purpose>\"\n",
    "                }}\n",
    "              ],\n",
    "              \"courses_taught\": [\n",
    "                {{\n",
    "                  \"title\": \"<Course Name>\",\n",
    "                  \"duration\": \"<Start Date - End Date>\",\n",
    "                  \"description\": \"<Brief description of the course and topics covered>\"\n",
    "                }}\n",
    "              ],\n",
    "              \"clubs_and_community\": [\n",
    "                {{\n",
    "                  \"name\": \"<Club or Organization Name>\",\n",
    "                  \"role\": \"<Role in the Organization>\",\n",
    "                  \"description\": \"<Contributions and activities>\"\n",
    "                }}\n",
    "              ],\n",
    "              \"achievements\": [\n",
    "                {{\n",
    "                  \"event\": \"<Event or Competition Name>\",\n",
    "                  \"placement\": \"<Rank or Award>\",\n",
    "                  \"description\": \"<Brief details on the competition and accomplishment>\"\n",
    "                }}\n",
    "              ],\n",
    "              \"publications\": [\n",
    "                {{\n",
    "                \"title\": \"<Publication Title>\",\n",
    "                \"authors\": [\"<Author 1>\", \"<Author 2>\", \"...\"],\n",
    "                \"journal_or_conference\": \"<Journal or Conference Name>\",\n",
    "                \"year\": \"<Year of Publication>\",\n",
    "                \"doi\": \"<DOI or URL>\",\n",
    "                \"abstract\": \"<Brief summary of the publication>\"\n",
    "                }}\n",
    "                ]\n",
    "            }}\n",
    "    \"\"\"\n",
    "\n",
    "    chain = prompt | llm  # Ensure `llm` is defined correctly\n",
    "\n",
    "    # Parse the file with LlamaParse\n",
    "    parsed_data = LlamaParse(result_type=\"markdown\", system_prompt=parsing_instruction).load_data(file_path)\n",
    "    raw_text = parsed_data[0].text if parsed_data else \"\"\n",
    "\n",
    "    if not raw_text:\n",
    "        print(\"Error: No data extracted from the file.\")\n",
    "        return None, None\n",
    "\n",
    "    # input_data = {\n",
    "    #     \"input_type\": \"Json format in the form of string\",\n",
    "    #     \"output_type\": \"Json format in the form of string\",\n",
    "    #     \"input\": raw_text\n",
    "    # }\n",
    "     \n",
    "    input_data = {\n",
    "        # \"input_type\": \"Json format in the form of string\",\n",
    "        # \"output_type\": \"Json format in the form of string\",\n",
    "        \"question\": raw_text\n",
    "    }\n",
    "\n",
    "    response = chain.invoke(input_data)\n",
    "\n",
    "    if not response or not response.content:\n",
    "        print(\"Error: No response from chain\")\n",
    "        return None, raw_text\n",
    "\n",
    "    # Extract JSON content from the response\n",
    "    match = re.search(r'```json\\n(.*?)\\n```', response.content, re.DOTALL)\n",
    "    cleaned_json_string = match.group(1).strip() if match else response.content.strip()\n",
    "    print(cleaned_json_string)\n",
    "    if not cleaned_json_string:\n",
    "        print(\"Error: Received empty JSON response\")\n",
    "        return None, raw_text\n",
    "\n",
    "    try:\n",
    "        json_data = json.loads(cleaned_json_string)\n",
    "        return json_data, raw_text\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Error Parsing JSON:\", e)\n",
    "        print(\"Raw JSON String:\", cleaned_json_string)  # Debugging\n",
    "        return None, raw_text"
   ],
   "id": "f5efe3d7f77eb478",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:28:02.213097Z",
     "start_time": "2025-04-11T13:28:02.200558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def aggMetadata(directory):\n",
    "    storage = {}\n",
    "    storage_text = {}\n",
    "    missing_contact_info = {}\n",
    "\n",
    "    for file_path in directory:\n",
    "        profile_data, profile_text = get_education_profile(file_path)\n",
    "\n",
    "        # Check if profile_data is None\n",
    "        if profile_data is None:\n",
    "            print(f\"Warning: No profile data extracted for {file_path}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Try extracting contact info\n",
    "        contact_info = profile_data.get(\"contact_information\", {}).get(\"contact\", {}).get(\"email\")\n",
    "\n",
    "        if contact_info:\n",
    "            storage[contact_info] = profile_data\n",
    "            storage_text[contact_info] = profile_text\n",
    "        else:\n",
    "            print(f\"Warning: Missing contact information for {file_path}. Marking for further processing.\")\n",
    "            missing_contact_info[file_path] = profile_data\n",
    "    \n",
    "    return storage, storage_text, missing_contact_info"
   ],
   "id": "27147f31fa7b1c31",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:28:02.228788Z",
     "start_time": "2025-04-11T13:28:02.216091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fix_missing_contact_info(missing_entries):\n",
    "    fixed_storage = {}\n",
    "\n",
    "    for file_path, profile_data in missing_entries.items():\n",
    "        # Attempt to extract from different fields\n",
    "        contact_info = (\n",
    "            profile_data.get(\"contact_information\", {}).get(\"contact\", {}).get(\"phone\") or\n",
    "            profile_data.get(\"contact_information\", {}).get(\"contact\", {}).get(\"linkedin\") or\n",
    "            profile_data.get(\"contact_information\", {}).get(\"contact\", {}).get(\"github\")\n",
    "        )\n",
    "\n",
    "        if contact_info:\n",
    "            print(f\"Recovered contact info for {file_path} using alternative fields.\")\n",
    "            fixed_storage[contact_info] = profile_data\n",
    "        else:\n",
    "            print(f\"Still missing contact info for {file_path}. Keeping it under its filename as key.\")\n",
    "            fixed_storage[file_path] = profile_data  # Use file path as fallback key\n",
    "\n",
    "    return fixed_storage"
   ],
   "id": "a6553390db8d2e42",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:16.111775Z",
     "start_time": "2025-04-11T13:28:02.231803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resultant_metadata, resultant_metadata_text, missing_contact_info = aggMetadata(output_directory_list)\n",
    "fixed_storage = fix_missing_contact_info(missing_entries=missing_contact_info)"
   ],
   "id": "53c5f6a9f1ac049a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 2c7273e2-bef2-4eb2-83e2-8e3ad2bf073f\n",
      "{\n",
      "  \"contact_information\": {\n",
      "    \"name\": \"Neville Joseph Sabu\",\n",
      "    \"contact\": {\n",
      "      \"phone\": \"+91-9747953669\",\n",
      "      \"email\": \"nevillejs24@gmail.com\",\n",
      "      \"github\": \"https://github.com/neb0lle\",\n",
      "      \"linkedin\": \"\",\n",
      "      \"website\": \"\"\n",
      "    }\n",
      "  },\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"institution\": \"PES University\",\n",
      "      \"degree\": \"Bachelor of Technology\",\n",
      "      \"field_of_study\": \"Computer Science and Engineering\",\n",
      "      \"duration\": \"2022 - Present\",\n",
      "      \"location\": \"Bangalore, India\",\n",
      "      \"GPA\": \"\"\n",
      "    }\n",
      "  ],\n",
      "  \"experience\": [\n",
      "    {\n",
      "      \"company\": \"BOSCH\",\n",
      "      \"position\": \"Project Intern - .NET Framework\",\n",
      "      \"duration\": \"April 2024 - Present\",\n",
      "      \"location\": \"Bangalore, India\",\n",
      "      \"responsibilities\": [\n",
      "        \"Designed and built configurable data visualization tools for RPS data analysis, enabling parameter adjustments for better insights.\",\n",
      "        \"Implemented a binary ARIMA model from scratch in C# to forecast events using binary time series modeling.\",\n",
      "        \"Designed the software for easy integration with existing systems, with rigorous testing underway to ensure reliability and performance.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"company\": \"PESU I/O\",\n",
      "      \"position\": \"Subject Matter Expert\",\n",
      "      \"duration\": \"October 2024 - November 2024\",\n",
      "      \"location\": \"Bangalore, India\",\n",
      "      \"responsibilities\": [\n",
      "        \"Designed and taught a game development course where students built a basic game engine from scratch using WebGL for rendering, implementing key game mechanics, graphics, and rendering techniques.\",\n",
      "        \"Delivered a comprehensive course on graphics programming with WebGL, covering shader programming, rendering techniques, and various graphics concepts.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"company\": \"Destination Designs\",\n",
      "      \"position\": \"Project Intern - Next.js, React, MongoDB, Node.js, AWS\",\n",
      "      \"duration\": \"September 2023 - January 2024\",\n",
      "      \"location\": \"Bangalore, India\",\n",
      "      \"responsibilities\": [\n",
      "        \"Developed an advanced image optimization pipeline that reduced load times, enhanced scalability, and lowered operational costs.\",\n",
      "        \"Created a dynamic and responsive user interface to display architecture projects using React, and transitioned database utilities from Express to Next.js Serverless functions, boosting performance and scalability.\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"technical_skills\": {\n",
      "    \"languages\": [\"Python\", \"C\", \"C++\", \"C#\", \"JavaScript\", \"Rust\", \"Golang\", \"Solidity\", \"SQL\"],\n",
      "    \"technologies\": [\"Linux\", \"Git\", \"GitHub\", \"OpenGL\", \"WebGL\", \"React\", \"Next.js\", \"Node.js\", \"Express\", \".NET\", \"AWS\"]\n",
      "  },\n",
      "  \"projects\": [\n",
      "    {\n",
      "      \"name\": \"wog\",\n",
      "      \"description\": \"A compact web-based 3D rendering engine built with WebGL, designed to render complex simulations and dynamic effects.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"daBlob\",\n",
      "      \"description\": \"A real-time simulation of Physarum slime using cellular automata, exploring and visualizing growth patterns and behaviors.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"raycst\",\n",
      "      \"description\": \"Raymarching implemented in OpenGL, showcasing advanced volumetric rendering techniques.\"\n",
      "    }\n",
      "  ],\n",
      "  \"courses_taught\": [],\n",
      "  \"clubs_and_community\": [\n",
      "    {\n",
      "      \"name\": \"ACM PESU-ECC\",\n",
      "      \"role\": \"Active member\",\n",
      "      \"description\": \"Contributing to the organization of hackathons and events, and offering mentorship and guidance to fellow peers.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Parallax PESU-ECC\",\n",
      "      \"role\": \"Core member\",\n",
      "      \"description\": \"Involved in organizing and hosting events, and mentoring peers.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Kalpana 2024\",\n",
      "      \"role\": \"Runners Up\",\n",
      "      \"description\": \"Secured second place in the Kalpana Hackathon, hosted by IEEE, by developing a blockchain-based charity platform that utilizes smart contracts.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"DeltaTime 2024\",\n",
      "      \"role\": \"2nd Runners Up\",\n",
      "      \"description\": \"Achieved third place in the DeltaTime 2024 Game Jam, organized by Parallax PESU.\"\n",
      "    }\n",
      "  ],\n",
      "  \"achievements\": [],\n",
      "  \"publications\": []\n",
      "}\n",
      "Started parsing the file under job_id 5e2f7841-8878-4d00-8eb9-a9934835e1ad\n",
      "{\n",
      "  \"contact_information\": {\n",
      "    \"name\": \"Nitheesh Pugazhanti\",\n",
      "    \"contact\": {\n",
      "      \"phone\": \"6363485819\",\n",
      "      \"email\": \"nith.pugazhanthi@gmail.com\",\n",
      "      \"github\": \"github.com/Noth2006\",\n",
      "      \"linkedin\": \"\",\n",
      "      \"website\": \"\"\n",
      "    }\n",
      "  },\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"institution\": \"PES University\",\n",
      "      \"degree\": \"Bachelor of Technology\",\n",
      "      \"field_of_study\": \"Computer Science and Engineering\",\n",
      "      \"duration\": \"2022 – 2026\",\n",
      "      \"location\": \"Bangalore, India\",\n",
      "      \"GPA\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"institution\": \"Presidency School Bangalore East\",\n",
      "      \"degree\": \"Grade 12\",\n",
      "      \"field_of_study\": \"N/A\",\n",
      "      \"duration\": \"2022\",\n",
      "      \"location\": \"Bangalore, India\",\n",
      "      \"GPA\": \"\"\n",
      "    }\n",
      "  ],\n",
      "  \"experience\": [],\n",
      "  \"technical_skills\": {\n",
      "    \"languages\": [\"Python\", \"C\", \"R\", \"Rust\", \"CUDA\", \"JavaScript\", \"HTML/CSS\", \"ARM Assembly\"],\n",
      "    \"technologies\": [\"pandas\", \"NumPy\", \"Matplotlib\", \"Pytorch\", \"tensorflow\", \"Git\", \"Kaggle\", \"Neovim\", \"Visual Studio\", \"PyCharm\", \"IntelliJ\", \"Rstudio\"]\n",
      "  },\n",
      "  \"projects\": [\n",
      "    {\n",
      "      \"name\": \"Implementation of a Virtual Machine for LC-3 Assembly Language Execution\",\n",
      "      \"description\": \"The VM supports the entire LC-3 instruction set, including operations such as arithmetic (ADD, AND), data movement (LD, ST), control flow (BR, JMP, JSR) and other operations (NOT, TRAP). Managed memory by implementing a 65,536 location array and an enum containing all the registers.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"ML based Intrusion Detection Systems with NodeMCU Esp-32 and UNSW-NB15\",\n",
      "      \"description\": \"It is a 2 level intrusion detection system, where the packet capture is performed by esp-32 micro controller. In the first level the incoming packet is matched with a database of all known malware signatures. In the second level the packets are passed on to classification ML models to detect zero-day attacks. Achieved up to 88% accuracy with feature extraction.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Recommendation System\",\n",
      "      \"description\": \"Developed a recommendation system in C using weighted graphs with adjacency lists to manage product relationships. Implemented a closest match algorithm to suggest related products based on assigned weights, improving recommendation accuracy. Has a custom json parser implemented using stacks to read input files.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Automated Text Analysis and New quality Index using a LLM\",\n",
      "      \"description\": \"Defined a new Quality Index formula that can be used to assess the quality of various documents for readability and cohesion. The fine-tuned LLM assesses the quality of each document and provides the final score.\"\n",
      "    }\n",
      "  ],\n",
      "  \"courses_taught\": [],\n",
      "  \"clubs_and_community\": [],\n",
      "  \"achievements\": [],\n",
      "  \"publications\": []\n",
      "}\n",
      "Started parsing the file under job_id a3f8cad0-1af0-42f8-8bbb-0549374ccfcf\n",
      "{\n",
      "  \"contact_information\": {\n",
      "    \"name\": \"Raghav Balakrishnan\",\n",
      "    \"contact\": {\n",
      "      \"phone\": \"+91 8296300963\",\n",
      "      \"email\": \"raghav.balakrishnan@gmail.com\",\n",
      "      \"github\": \"https://github.com/RaghavB1404\",\n",
      "      \"linkedin\": \"\",\n",
      "      \"website\": \"\"\n",
      "    }\n",
      "  },\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"institution\": \"PES University\",\n",
      "      \"degree\": \"Bachelor of Technology\",\n",
      "      \"field_of_study\": \"Computer Science\",\n",
      "      \"duration\": \"2022 - 2026\",\n",
      "      \"location\": \"Bangalore, India\",\n",
      "      \"GPA\": \"\"\n",
      "    },\n",
      "    {\n",
      "      \"institution\": \"Base PU College\",\n",
      "      \"degree\": \"Higher Secondary School\",\n",
      "      \"field_of_study\": \"\",\n",
      "      \"duration\": \"2020 - 2022\",\n",
      "      \"location\": \"Bangalore, India\",\n",
      "      \"GPA\": \"\"\n",
      "    }\n",
      "  ],\n",
      "  \"experience\": [\n",
      "    {\n",
      "      \"company\": \"Centre of Data Modelling, Analytics and Visualization, PES University\",\n",
      "      \"position\": \"Research Intern\",\n",
      "      \"duration\": \"Jun 2024 – Aug 2024\",\n",
      "      \"location\": \"Bangalore, India\",\n",
      "      \"responsibilities\": [\n",
      "        \"Engineered an advanced hybrid neural network model by combining Long Short-Term Memory (LSTM) networks with Kolmogorov Arnold Networks (KAN) for stock price forecasting.\",\n",
      "        \"Designed and implemented a robust data pipeline that integrates text data with numerical OHLC data to enhance predictive accuracy.\",\n",
      "        \"Developed and fine-tuned the hybrid model for algorithmic trading applications, resulting in improved predictive accuracy and trading strategy performance.\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"technical_skills\": {\n",
      "    \"languages\": [\"Python\", \"C\"],\n",
      "    \"technologies\": [\"TensorFlow\", \"Keras\", \"Pygame\", \"OpenCV\", \"Raspberry Pi\", \"MongoDB\", \"React.js\", \"Node.js\", \"Express.js\", \"Pandas\", \"Scikit-learn\", \"Matplotlib\", \"NumPy\"]\n",
      "  },\n",
      "  \"projects\": [\n",
      "    {\n",
      "      \"name\": \"Autonomous Car\",\n",
      "      \"description\": \"Designed and implemented an autonomous car using a Raspberry Pi and neural networks for navigation and decision-making.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Stock Portfolio Manager\",\n",
      "      \"description\": \"Created a stock market simulator to trade and manage portfolio using MERN stack and integrated APIs for real-time data feed.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Productivity Note Taking Tool\",\n",
      "      \"description\": \"Developed a note-taking tool using data structures and file system operations to enhance productivity and streamline note-taking processes.\"\n",
      "    }\n",
      "  ],\n",
      "  \"courses_taught\": [],\n",
      "  \"clubs_and_community\": [],\n",
      "  \"achievements\": [],\n",
      "  \"publications\": []\n",
      "}\n",
      "Started parsing the file under job_id 0980aeeb-8cba-4e07-936f-6a1e9ce04920\n",
      "{\n",
      "  \"contact_information\": {\n",
      "    \"name\": \"Rithul Rakesh\",\n",
      "    \"contact\": {\n",
      "      \"phone\": \"\",\n",
      "      \"email\": \"rithul1905@gmail.com\",\n",
      "      \"github\": \"GitHub\",\n",
      "      \"linkedin\": \"LinkedIn\",\n",
      "      \"website\": \"\"\n",
      "    }\n",
      "  },\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"institution\": \"PES UNIVERSITY\",\n",
      "      \"degree\": \"Bachelor of Technology\",\n",
      "      \"field_of_study\": \"Computer Science Engineering\",\n",
      "      \"duration\": \"Expected May 2026\",\n",
      "      \"location\": \"Bangalore, Karnataka\",\n",
      "      \"GPA\": null\n",
      "    }\n",
      "  ],\n",
      "  \"experience\": [\n",
      "    {\n",
      "      \"company\": \"CENTRE OF DATA MODELLING, ANALYTICS AND VISUALIZATION, PESU\",\n",
      "      \"position\": \"RESEARCH INTERN\",\n",
      "      \"duration\": \"Jun 2024 – Aug 2024\",\n",
      "      \"location\": \"Bangalore, Karnataka\",\n",
      "      \"responsibilities\": [\n",
      "        \"Tasked with developing a high-performance algorithmic trading system for volatile market conditions, focusing on combining traditional time-series analysis with real-time market sentiment data.\",\n",
      "        \"Led the design and implementation of a novel hybrid neural network architecture integrating Long Short-Term Memory (LSTM) networks with Kolmogorov Arnold Networks (KAN), optimizing for non-linear pattern recognition in financial time series.\",\n",
      "        \"Engineered an advanced data pipeline integrating vector databases, RAG pipeline, and FinBERT for comprehensive financial data processing, combining OHLC market data with real-time sentiment analysis from over 1000+ financial news articles spanning 30 days and 2 years of historical stock data.\",\n",
      "        \"Achieved 30% improvement in directional prediction accuracy compared to traditional LSTM models.\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"technical_skills\": {\n",
      "    \"languages\": [\"Python\", \"C\"],\n",
      "    \"technologies\": [\"TensorFlow\", \"PyTorch\", \"BERT\", \"RAG pipelines\", \"Vector Databases\", \"Kafka\", \"Hadoop\", \"Spark\", \"AWS Cloud Services\", \"React.js\", \"MongoDB\", \"MySQL\"]\n",
      "  },\n",
      "  \"projects\": [\n",
      "    {\n",
      "      \"name\": \"MULTIMODAL EMOTION CLASSIFICATION USING TEXT AND VIDEO FEATURES\",\n",
      "      \"description\": \"Developed a multimodal deep learning model for emotion classification, integrating BERT for textual embeddings and ResNet-50 for video frame analysis, enabling accurate sentiment prediction.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"BENCHMARKING TRANSFORMER MODELS FOR MULTI-TASK NLP APPLICATIONS\",\n",
      "      \"description\": \"Evaluated four state of the art transformer models; BERT, RoBERTa, BART, and GPT pipelines using Hugging Face’s Transformers library to perform advanced tasks such as summarization, text completion, question answering, and story generation.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"DISTRIBUTED LOGGING SYSTEM\",\n",
      "      \"description\": \"Designed and implemented a microservices-based logging architecture using Fluentd to collect logs from multiple nodes, and Apache Kafka for real-time log distribution.\"\n",
      "    }\n",
      "  ],\n",
      "  \"courses_taught\": [],\n",
      "  \"clubs_and_community\": [],\n",
      "  \"achievements\": [\n",
      "    {\n",
      "      \"event\": \"Academic Performance\",\n",
      "      \"placement\": \"3x recipient of Distinction and Scholarship\",\n",
      "      \"description\": \"Awarded for top academic performance in Computer Science Engineering.\"\n",
      "    }\n",
      "  ],\n",
      "  \"publications\": []\n",
      "}\n",
      "Started parsing the file under job_id b94c7eaf-3d50-404b-9916-cebed02a0a1e\n",
      "{\n",
      "  \"contact_information\": {\n",
      "    \"name\": \"Sreecharan Palepu\",\n",
      "    \"contact\": {\n",
      "      \"phone\": \"+919618403578\",\n",
      "      \"email\": \"\",\n",
      "      \"github\": \"\",\n",
      "      \"linkedin\": \"https://www.linkedin.com/in/sreecharan-p\",\n",
      "      \"website\": \"\"\n",
      "    }\n",
      "  },\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"institution\": \"PES University\",\n",
      "      \"degree\": \"Bachelor of Technology\",\n",
      "      \"field_of_study\": \"Computer Science and Engineering\",\n",
      "      \"duration\": \"Present\",\n",
      "      \"location\": \"Bangalore, India\",\n",
      "      \"GPA\": null\n",
      "    }\n",
      "  ],\n",
      "  \"experience\": [\n",
      "    {\n",
      "      \"company\": \"PES University\",\n",
      "      \"position\": \"Research Intern\",\n",
      "      \"duration\": \"June 2024 - Present\",\n",
      "      \"location\": \"Bangalore, India\",\n",
      "      \"responsibilities\": [\n",
      "        \"Applicating LLM’s and algorithmic retrieval techniques to find the research gap and finding a suitable model for a dataset.\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"technical_skills\": {\n",
      "    \"languages\": [\"Python\", \"C/C++\", \"R\"],\n",
      "    \"technologies\": [\n",
      "      \"pandas\",\n",
      "      \"numpy\",\n",
      "      \"scikit-learn\",\n",
      "      \"HuggingFace\",\n",
      "      \"NLTK\",\n",
      "      \"Keras\",\n",
      "      \"Langchain\",\n",
      "      \"TensorFlow\",\n",
      "      \"Git\",\n",
      "      \"MongoDB\",\n",
      "      \"SQL\",\n",
      "      \"Spacy\",\n",
      "      \"LlamaIndex\",\n",
      "      \"Pydantic\"\n",
      "    ]\n",
      "  },\n",
      "  \"projects\": [\n",
      "    {\n",
      "      \"name\": \"Real-Time Stock Price Tracking and Analysis\",\n",
      "      \"description\": \"Created StockWatch Pro, a Python tool for scraping real-time stock prices, creating watch lists, and analyzing stock statistics using DearPyGui.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"LLM-Powered Multimodal Research Gap Analysis and Model Recommendation System\",\n",
      "      \"description\": \"Developed an LLM-powered system to analyze research papers and identify research gaps. The system evaluates performance against other models and conducts comprehensive dataset analysis. It recommends suitable models for specific tasks based on the contextual information.\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"HR-Driven Semantic Metadata System for Resume Filtering, Querying, and Ranking\",\n",
      "      \"description\": \"Developing an application to improve shortlisting efficiency by evaluating candidates comprehensively, including GitHub profiles, project assessments, and other relevant metrics.\"\n",
      "    }\n",
      "  ],\n",
      "  \"courses_taught\": [],\n",
      "  \"clubs_and_community\": [\n",
      "    {\n",
      "      \"name\": \"Qforest\",\n",
      "      \"role\": \"Marketing & Sponsorship\",\n",
      "      \"description\": \"Played a key role in securing sponsorships, including a partnership with Honeywell, and managed budgets and finances for club events to ensure their success.\"\n",
      "    }\n",
      "  ],\n",
      "  \"achievements\": [],\n",
      "  \"publications\": [\n",
      "    {\n",
      "      \"title\": \"LLM-Powered Multimodal Research Gap Analysis and Model Recommendation System\",\n",
      "      \"authors\": [],\n",
      "      \"journal_or_conference\": \"Paper publication in progress\",\n",
      "      \"year\": \"\",\n",
      "      \"doi\": \"\",\n",
      "      \"abstract\": \"\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Warning: Missing contact information for C:\\Users\\sreec\\PycharmProjects\\ENTERPRISE_RAG\\GENAI_PROJECT\\GoogleDriveFiles\\Sreecharan_pes_updated (3).pdf. Marking for further processing.\n",
      "Recovered contact info for C:\\Users\\sreec\\PycharmProjects\\ENTERPRISE_RAG\\GENAI_PROJECT\\GoogleDriveFiles\\Sreecharan_pes_updated (3).pdf using alternative fields.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:16.126633Z",
     "start_time": "2025-04-11T13:29:16.114775Z"
    }
   },
   "cell_type": "code",
   "source": "missing_contact_info",
   "id": "d7179fc6c389af0d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C:\\\\Users\\\\sreec\\\\PycharmProjects\\\\ENTERPRISE_RAG\\\\GENAI_PROJECT\\\\GoogleDriveFiles\\\\Sreecharan_pes_updated (3).pdf': {'contact_information': {'name': 'Sreecharan Palepu',\n",
       "   'contact': {'phone': '+919618403578',\n",
       "    'email': '',\n",
       "    'github': '',\n",
       "    'linkedin': 'https://www.linkedin.com/in/sreecharan-p',\n",
       "    'website': ''}},\n",
       "  'education': [{'institution': 'PES University',\n",
       "    'degree': 'Bachelor of Technology',\n",
       "    'field_of_study': 'Computer Science and Engineering',\n",
       "    'duration': 'Present',\n",
       "    'location': 'Bangalore, India',\n",
       "    'GPA': None}],\n",
       "  'experience': [{'company': 'PES University',\n",
       "    'position': 'Research Intern',\n",
       "    'duration': 'June 2024 - Present',\n",
       "    'location': 'Bangalore, India',\n",
       "    'responsibilities': ['Applicating LLM’s and algorithmic retrieval techniques to find the research gap and finding a suitable model for a dataset.']}],\n",
       "  'technical_skills': {'languages': ['Python', 'C/C++', 'R'],\n",
       "   'technologies': ['pandas',\n",
       "    'numpy',\n",
       "    'scikit-learn',\n",
       "    'HuggingFace',\n",
       "    'NLTK',\n",
       "    'Keras',\n",
       "    'Langchain',\n",
       "    'TensorFlow',\n",
       "    'Git',\n",
       "    'MongoDB',\n",
       "    'SQL',\n",
       "    'Spacy',\n",
       "    'LlamaIndex',\n",
       "    'Pydantic']},\n",
       "  'projects': [{'name': 'Real-Time Stock Price Tracking and Analysis',\n",
       "    'description': 'Created StockWatch Pro, a Python tool for scraping real-time stock prices, creating watch lists, and analyzing stock statistics using DearPyGui.'},\n",
       "   {'name': 'LLM-Powered Multimodal Research Gap Analysis and Model Recommendation System',\n",
       "    'description': 'Developed an LLM-powered system to analyze research papers and identify research gaps. The system evaluates performance against other models and conducts comprehensive dataset analysis. It recommends suitable models for specific tasks based on the contextual information.'},\n",
       "   {'name': 'HR-Driven Semantic Metadata System for Resume Filtering, Querying, and Ranking',\n",
       "    'description': 'Developing an application to improve shortlisting efficiency by evaluating candidates comprehensively, including GitHub profiles, project assessments, and other relevant metrics.'}],\n",
       "  'courses_taught': [],\n",
       "  'clubs_and_community': [{'name': 'Qforest',\n",
       "    'role': 'Marketing & Sponsorship',\n",
       "    'description': 'Played a key role in securing sponsorships, including a partnership with Honeywell, and managed budgets and finances for club events to ensure their success.'}],\n",
       "  'achievements': [],\n",
       "  'publications': [{'title': 'LLM-Powered Multimodal Research Gap Analysis and Model Recommendation System',\n",
       "    'authors': [],\n",
       "    'journal_or_conference': 'Paper publication in progress',\n",
       "    'year': '',\n",
       "    'doi': '',\n",
       "    'abstract': ''}]}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:16.345125Z",
     "start_time": "2025-04-11T13:29:16.128989Z"
    }
   },
   "cell_type": "code",
   "source": "fixed_storage",
   "id": "531cf8b1c14fa10d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'+919618403578': {'contact_information': {'name': 'Sreecharan Palepu',\n",
       "   'contact': {'phone': '+919618403578',\n",
       "    'email': '',\n",
       "    'github': '',\n",
       "    'linkedin': 'https://www.linkedin.com/in/sreecharan-p',\n",
       "    'website': ''}},\n",
       "  'education': [{'institution': 'PES University',\n",
       "    'degree': 'Bachelor of Technology',\n",
       "    'field_of_study': 'Computer Science and Engineering',\n",
       "    'duration': 'Present',\n",
       "    'location': 'Bangalore, India',\n",
       "    'GPA': None}],\n",
       "  'experience': [{'company': 'PES University',\n",
       "    'position': 'Research Intern',\n",
       "    'duration': 'June 2024 - Present',\n",
       "    'location': 'Bangalore, India',\n",
       "    'responsibilities': ['Applicating LLM’s and algorithmic retrieval techniques to find the research gap and finding a suitable model for a dataset.']}],\n",
       "  'technical_skills': {'languages': ['Python', 'C/C++', 'R'],\n",
       "   'technologies': ['pandas',\n",
       "    'numpy',\n",
       "    'scikit-learn',\n",
       "    'HuggingFace',\n",
       "    'NLTK',\n",
       "    'Keras',\n",
       "    'Langchain',\n",
       "    'TensorFlow',\n",
       "    'Git',\n",
       "    'MongoDB',\n",
       "    'SQL',\n",
       "    'Spacy',\n",
       "    'LlamaIndex',\n",
       "    'Pydantic']},\n",
       "  'projects': [{'name': 'Real-Time Stock Price Tracking and Analysis',\n",
       "    'description': 'Created StockWatch Pro, a Python tool for scraping real-time stock prices, creating watch lists, and analyzing stock statistics using DearPyGui.'},\n",
       "   {'name': 'LLM-Powered Multimodal Research Gap Analysis and Model Recommendation System',\n",
       "    'description': 'Developed an LLM-powered system to analyze research papers and identify research gaps. The system evaluates performance against other models and conducts comprehensive dataset analysis. It recommends suitable models for specific tasks based on the contextual information.'},\n",
       "   {'name': 'HR-Driven Semantic Metadata System for Resume Filtering, Querying, and Ranking',\n",
       "    'description': 'Developing an application to improve shortlisting efficiency by evaluating candidates comprehensively, including GitHub profiles, project assessments, and other relevant metrics.'}],\n",
       "  'courses_taught': [],\n",
       "  'clubs_and_community': [{'name': 'Qforest',\n",
       "    'role': 'Marketing & Sponsorship',\n",
       "    'description': 'Played a key role in securing sponsorships, including a partnership with Honeywell, and managed budgets and finances for club events to ensure their success.'}],\n",
       "  'achievements': [],\n",
       "  'publications': [{'title': 'LLM-Powered Multimodal Research Gap Analysis and Model Recommendation System',\n",
       "    'authors': [],\n",
       "    'journal_or_conference': 'Paper publication in progress',\n",
       "    'year': '',\n",
       "    'doi': '',\n",
       "    'abstract': ''}]}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:16.375709Z",
     "start_time": "2025-04-11T13:29:16.348126Z"
    }
   },
   "cell_type": "code",
   "source": "resultant_metadata",
   "id": "d52e9606a6c3f0ba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nevillejs24@gmail.com': {'contact_information': {'name': 'Neville Joseph Sabu',\n",
       "   'contact': {'phone': '+91-9747953669',\n",
       "    'email': 'nevillejs24@gmail.com',\n",
       "    'github': 'https://github.com/neb0lle',\n",
       "    'linkedin': '',\n",
       "    'website': ''}},\n",
       "  'education': [{'institution': 'PES University',\n",
       "    'degree': 'Bachelor of Technology',\n",
       "    'field_of_study': 'Computer Science and Engineering',\n",
       "    'duration': '2022 - Present',\n",
       "    'location': 'Bangalore, India',\n",
       "    'GPA': ''}],\n",
       "  'experience': [{'company': 'BOSCH',\n",
       "    'position': 'Project Intern - .NET Framework',\n",
       "    'duration': 'April 2024 - Present',\n",
       "    'location': 'Bangalore, India',\n",
       "    'responsibilities': ['Designed and built configurable data visualization tools for RPS data analysis, enabling parameter adjustments for better insights.',\n",
       "     'Implemented a binary ARIMA model from scratch in C# to forecast events using binary time series modeling.',\n",
       "     'Designed the software for easy integration with existing systems, with rigorous testing underway to ensure reliability and performance.']},\n",
       "   {'company': 'PESU I/O',\n",
       "    'position': 'Subject Matter Expert',\n",
       "    'duration': 'October 2024 - November 2024',\n",
       "    'location': 'Bangalore, India',\n",
       "    'responsibilities': ['Designed and taught a game development course where students built a basic game engine from scratch using WebGL for rendering, implementing key game mechanics, graphics, and rendering techniques.',\n",
       "     'Delivered a comprehensive course on graphics programming with WebGL, covering shader programming, rendering techniques, and various graphics concepts.']},\n",
       "   {'company': 'Destination Designs',\n",
       "    'position': 'Project Intern - Next.js, React, MongoDB, Node.js, AWS',\n",
       "    'duration': 'September 2023 - January 2024',\n",
       "    'location': 'Bangalore, India',\n",
       "    'responsibilities': ['Developed an advanced image optimization pipeline that reduced load times, enhanced scalability, and lowered operational costs.',\n",
       "     'Created a dynamic and responsive user interface to display architecture projects using React, and transitioned database utilities from Express to Next.js Serverless functions, boosting performance and scalability.']}],\n",
       "  'technical_skills': {'languages': ['Python',\n",
       "    'C',\n",
       "    'C++',\n",
       "    'C#',\n",
       "    'JavaScript',\n",
       "    'Rust',\n",
       "    'Golang',\n",
       "    'Solidity',\n",
       "    'SQL'],\n",
       "   'technologies': ['Linux',\n",
       "    'Git',\n",
       "    'GitHub',\n",
       "    'OpenGL',\n",
       "    'WebGL',\n",
       "    'React',\n",
       "    'Next.js',\n",
       "    'Node.js',\n",
       "    'Express',\n",
       "    '.NET',\n",
       "    'AWS']},\n",
       "  'projects': [{'name': 'wog',\n",
       "    'description': 'A compact web-based 3D rendering engine built with WebGL, designed to render complex simulations and dynamic effects.'},\n",
       "   {'name': 'daBlob',\n",
       "    'description': 'A real-time simulation of Physarum slime using cellular automata, exploring and visualizing growth patterns and behaviors.'},\n",
       "   {'name': 'raycst',\n",
       "    'description': 'Raymarching implemented in OpenGL, showcasing advanced volumetric rendering techniques.'}],\n",
       "  'courses_taught': [],\n",
       "  'clubs_and_community': [{'name': 'ACM PESU-ECC',\n",
       "    'role': 'Active member',\n",
       "    'description': 'Contributing to the organization of hackathons and events, and offering mentorship and guidance to fellow peers.'},\n",
       "   {'name': 'Parallax PESU-ECC',\n",
       "    'role': 'Core member',\n",
       "    'description': 'Involved in organizing and hosting events, and mentoring peers.'},\n",
       "   {'name': 'Kalpana 2024',\n",
       "    'role': 'Runners Up',\n",
       "    'description': 'Secured second place in the Kalpana Hackathon, hosted by IEEE, by developing a blockchain-based charity platform that utilizes smart contracts.'},\n",
       "   {'name': 'DeltaTime 2024',\n",
       "    'role': '2nd Runners Up',\n",
       "    'description': 'Achieved third place in the DeltaTime 2024 Game Jam, organized by Parallax PESU.'}],\n",
       "  'achievements': [],\n",
       "  'publications': []},\n",
       " 'nith.pugazhanthi@gmail.com': {'contact_information': {'name': 'Nitheesh Pugazhanti',\n",
       "   'contact': {'phone': '6363485819',\n",
       "    'email': 'nith.pugazhanthi@gmail.com',\n",
       "    'github': 'github.com/Noth2006',\n",
       "    'linkedin': '',\n",
       "    'website': ''}},\n",
       "  'education': [{'institution': 'PES University',\n",
       "    'degree': 'Bachelor of Technology',\n",
       "    'field_of_study': 'Computer Science and Engineering',\n",
       "    'duration': '2022 – 2026',\n",
       "    'location': 'Bangalore, India',\n",
       "    'GPA': ''},\n",
       "   {'institution': 'Presidency School Bangalore East',\n",
       "    'degree': 'Grade 12',\n",
       "    'field_of_study': 'N/A',\n",
       "    'duration': '2022',\n",
       "    'location': 'Bangalore, India',\n",
       "    'GPA': ''}],\n",
       "  'experience': [],\n",
       "  'technical_skills': {'languages': ['Python',\n",
       "    'C',\n",
       "    'R',\n",
       "    'Rust',\n",
       "    'CUDA',\n",
       "    'JavaScript',\n",
       "    'HTML/CSS',\n",
       "    'ARM Assembly'],\n",
       "   'technologies': ['pandas',\n",
       "    'NumPy',\n",
       "    'Matplotlib',\n",
       "    'Pytorch',\n",
       "    'tensorflow',\n",
       "    'Git',\n",
       "    'Kaggle',\n",
       "    'Neovim',\n",
       "    'Visual Studio',\n",
       "    'PyCharm',\n",
       "    'IntelliJ',\n",
       "    'Rstudio']},\n",
       "  'projects': [{'name': 'Implementation of a Virtual Machine for LC-3 Assembly Language Execution',\n",
       "    'description': 'The VM supports the entire LC-3 instruction set, including operations such as arithmetic (ADD, AND), data movement (LD, ST), control flow (BR, JMP, JSR) and other operations (NOT, TRAP). Managed memory by implementing a 65,536 location array and an enum containing all the registers.'},\n",
       "   {'name': 'ML based Intrusion Detection Systems with NodeMCU Esp-32 and UNSW-NB15',\n",
       "    'description': 'It is a 2 level intrusion detection system, where the packet capture is performed by esp-32 micro controller. In the first level the incoming packet is matched with a database of all known malware signatures. In the second level the packets are passed on to classification ML models to detect zero-day attacks. Achieved up to 88% accuracy with feature extraction.'},\n",
       "   {'name': 'Recommendation System',\n",
       "    'description': 'Developed a recommendation system in C using weighted graphs with adjacency lists to manage product relationships. Implemented a closest match algorithm to suggest related products based on assigned weights, improving recommendation accuracy. Has a custom json parser implemented using stacks to read input files.'},\n",
       "   {'name': 'Automated Text Analysis and New quality Index using a LLM',\n",
       "    'description': 'Defined a new Quality Index formula that can be used to assess the quality of various documents for readability and cohesion. The fine-tuned LLM assesses the quality of each document and provides the final score.'}],\n",
       "  'courses_taught': [],\n",
       "  'clubs_and_community': [],\n",
       "  'achievements': [],\n",
       "  'publications': []},\n",
       " 'raghav.balakrishnan@gmail.com': {'contact_information': {'name': 'Raghav Balakrishnan',\n",
       "   'contact': {'phone': '+91 8296300963',\n",
       "    'email': 'raghav.balakrishnan@gmail.com',\n",
       "    'github': 'https://github.com/RaghavB1404',\n",
       "    'linkedin': '',\n",
       "    'website': ''}},\n",
       "  'education': [{'institution': 'PES University',\n",
       "    'degree': 'Bachelor of Technology',\n",
       "    'field_of_study': 'Computer Science',\n",
       "    'duration': '2022 - 2026',\n",
       "    'location': 'Bangalore, India',\n",
       "    'GPA': ''},\n",
       "   {'institution': 'Base PU College',\n",
       "    'degree': 'Higher Secondary School',\n",
       "    'field_of_study': '',\n",
       "    'duration': '2020 - 2022',\n",
       "    'location': 'Bangalore, India',\n",
       "    'GPA': ''}],\n",
       "  'experience': [{'company': 'Centre of Data Modelling, Analytics and Visualization, PES University',\n",
       "    'position': 'Research Intern',\n",
       "    'duration': 'Jun 2024 – Aug 2024',\n",
       "    'location': 'Bangalore, India',\n",
       "    'responsibilities': ['Engineered an advanced hybrid neural network model by combining Long Short-Term Memory (LSTM) networks with Kolmogorov Arnold Networks (KAN) for stock price forecasting.',\n",
       "     'Designed and implemented a robust data pipeline that integrates text data with numerical OHLC data to enhance predictive accuracy.',\n",
       "     'Developed and fine-tuned the hybrid model for algorithmic trading applications, resulting in improved predictive accuracy and trading strategy performance.']}],\n",
       "  'technical_skills': {'languages': ['Python', 'C'],\n",
       "   'technologies': ['TensorFlow',\n",
       "    'Keras',\n",
       "    'Pygame',\n",
       "    'OpenCV',\n",
       "    'Raspberry Pi',\n",
       "    'MongoDB',\n",
       "    'React.js',\n",
       "    'Node.js',\n",
       "    'Express.js',\n",
       "    'Pandas',\n",
       "    'Scikit-learn',\n",
       "    'Matplotlib',\n",
       "    'NumPy']},\n",
       "  'projects': [{'name': 'Autonomous Car',\n",
       "    'description': 'Designed and implemented an autonomous car using a Raspberry Pi and neural networks for navigation and decision-making.'},\n",
       "   {'name': 'Stock Portfolio Manager',\n",
       "    'description': 'Created a stock market simulator to trade and manage portfolio using MERN stack and integrated APIs for real-time data feed.'},\n",
       "   {'name': 'Productivity Note Taking Tool',\n",
       "    'description': 'Developed a note-taking tool using data structures and file system operations to enhance productivity and streamline note-taking processes.'}],\n",
       "  'courses_taught': [],\n",
       "  'clubs_and_community': [],\n",
       "  'achievements': [],\n",
       "  'publications': []},\n",
       " 'rithul1905@gmail.com': {'contact_information': {'name': 'Rithul Rakesh',\n",
       "   'contact': {'phone': '',\n",
       "    'email': 'rithul1905@gmail.com',\n",
       "    'github': 'GitHub',\n",
       "    'linkedin': 'LinkedIn',\n",
       "    'website': ''}},\n",
       "  'education': [{'institution': 'PES UNIVERSITY',\n",
       "    'degree': 'Bachelor of Technology',\n",
       "    'field_of_study': 'Computer Science Engineering',\n",
       "    'duration': 'Expected May 2026',\n",
       "    'location': 'Bangalore, Karnataka',\n",
       "    'GPA': None}],\n",
       "  'experience': [{'company': 'CENTRE OF DATA MODELLING, ANALYTICS AND VISUALIZATION, PESU',\n",
       "    'position': 'RESEARCH INTERN',\n",
       "    'duration': 'Jun 2024 – Aug 2024',\n",
       "    'location': 'Bangalore, Karnataka',\n",
       "    'responsibilities': ['Tasked with developing a high-performance algorithmic trading system for volatile market conditions, focusing on combining traditional time-series analysis with real-time market sentiment data.',\n",
       "     'Led the design and implementation of a novel hybrid neural network architecture integrating Long Short-Term Memory (LSTM) networks with Kolmogorov Arnold Networks (KAN), optimizing for non-linear pattern recognition in financial time series.',\n",
       "     'Engineered an advanced data pipeline integrating vector databases, RAG pipeline, and FinBERT for comprehensive financial data processing, combining OHLC market data with real-time sentiment analysis from over 1000+ financial news articles spanning 30 days and 2 years of historical stock data.',\n",
       "     'Achieved 30% improvement in directional prediction accuracy compared to traditional LSTM models.']}],\n",
       "  'technical_skills': {'languages': ['Python', 'C'],\n",
       "   'technologies': ['TensorFlow',\n",
       "    'PyTorch',\n",
       "    'BERT',\n",
       "    'RAG pipelines',\n",
       "    'Vector Databases',\n",
       "    'Kafka',\n",
       "    'Hadoop',\n",
       "    'Spark',\n",
       "    'AWS Cloud Services',\n",
       "    'React.js',\n",
       "    'MongoDB',\n",
       "    'MySQL']},\n",
       "  'projects': [{'name': 'MULTIMODAL EMOTION CLASSIFICATION USING TEXT AND VIDEO FEATURES',\n",
       "    'description': 'Developed a multimodal deep learning model for emotion classification, integrating BERT for textual embeddings and ResNet-50 for video frame analysis, enabling accurate sentiment prediction.'},\n",
       "   {'name': 'BENCHMARKING TRANSFORMER MODELS FOR MULTI-TASK NLP APPLICATIONS',\n",
       "    'description': 'Evaluated four state of the art transformer models; BERT, RoBERTa, BART, and GPT pipelines using Hugging Face’s Transformers library to perform advanced tasks such as summarization, text completion, question answering, and story generation.'},\n",
       "   {'name': 'DISTRIBUTED LOGGING SYSTEM',\n",
       "    'description': 'Designed and implemented a microservices-based logging architecture using Fluentd to collect logs from multiple nodes, and Apache Kafka for real-time log distribution.'}],\n",
       "  'courses_taught': [],\n",
       "  'clubs_and_community': [],\n",
       "  'achievements': [{'event': 'Academic Performance',\n",
       "    'placement': '3x recipient of Distinction and Scholarship',\n",
       "    'description': 'Awarded for top academic performance in Computer Science Engineering.'}],\n",
       "  'publications': []}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:16.391222Z",
     "start_time": "2025-04-11T13:29:16.377712Z"
    }
   },
   "cell_type": "code",
   "source": "resultant_metadata_combined = {**resultant_metadata, **fixed_storage}",
   "id": "49a3d8ec5c7937c9",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:16.422669Z",
     "start_time": "2025-04-11T13:29:16.394543Z"
    }
   },
   "cell_type": "code",
   "source": "resultant_metadata_combined",
   "id": "18ed653a730c710a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nevillejs24@gmail.com': {'contact_information': {'name': 'Neville Joseph Sabu',\n",
       "   'contact': {'phone': '+91-9747953669',\n",
       "    'email': 'nevillejs24@gmail.com',\n",
       "    'github': 'https://github.com/neb0lle',\n",
       "    'linkedin': '',\n",
       "    'website': ''}},\n",
       "  'education': [{'institution': 'PES University',\n",
       "    'degree': 'Bachelor of Technology',\n",
       "    'field_of_study': 'Computer Science and Engineering',\n",
       "    'duration': '2022 - Present',\n",
       "    'location': 'Bangalore, India',\n",
       "    'GPA': ''}],\n",
       "  'experience': [{'company': 'BOSCH',\n",
       "    'position': 'Project Intern - .NET Framework',\n",
       "    'duration': 'April 2024 - Present',\n",
       "    'location': 'Bangalore, India',\n",
       "    'responsibilities': ['Designed and built configurable data visualization tools for RPS data analysis, enabling parameter adjustments for better insights.',\n",
       "     'Implemented a binary ARIMA model from scratch in C# to forecast events using binary time series modeling.',\n",
       "     'Designed the software for easy integration with existing systems, with rigorous testing underway to ensure reliability and performance.']},\n",
       "   {'company': 'PESU I/O',\n",
       "    'position': 'Subject Matter Expert',\n",
       "    'duration': 'October 2024 - November 2024',\n",
       "    'location': 'Bangalore, India',\n",
       "    'responsibilities': ['Designed and taught a game development course where students built a basic game engine from scratch using WebGL for rendering, implementing key game mechanics, graphics, and rendering techniques.',\n",
       "     'Delivered a comprehensive course on graphics programming with WebGL, covering shader programming, rendering techniques, and various graphics concepts.']},\n",
       "   {'company': 'Destination Designs',\n",
       "    'position': 'Project Intern - Next.js, React, MongoDB, Node.js, AWS',\n",
       "    'duration': 'September 2023 - January 2024',\n",
       "    'location': 'Bangalore, India',\n",
       "    'responsibilities': ['Developed an advanced image optimization pipeline that reduced load times, enhanced scalability, and lowered operational costs.',\n",
       "     'Created a dynamic and responsive user interface to display architecture projects using React, and transitioned database utilities from Express to Next.js Serverless functions, boosting performance and scalability.']}],\n",
       "  'technical_skills': {'languages': ['Python',\n",
       "    'C',\n",
       "    'C++',\n",
       "    'C#',\n",
       "    'JavaScript',\n",
       "    'Rust',\n",
       "    'Golang',\n",
       "    'Solidity',\n",
       "    'SQL'],\n",
       "   'technologies': ['Linux',\n",
       "    'Git',\n",
       "    'GitHub',\n",
       "    'OpenGL',\n",
       "    'WebGL',\n",
       "    'React',\n",
       "    'Next.js',\n",
       "    'Node.js',\n",
       "    'Express',\n",
       "    '.NET',\n",
       "    'AWS']},\n",
       "  'projects': [{'name': 'wog',\n",
       "    'description': 'A compact web-based 3D rendering engine built with WebGL, designed to render complex simulations and dynamic effects.'},\n",
       "   {'name': 'daBlob',\n",
       "    'description': 'A real-time simulation of Physarum slime using cellular automata, exploring and visualizing growth patterns and behaviors.'},\n",
       "   {'name': 'raycst',\n",
       "    'description': 'Raymarching implemented in OpenGL, showcasing advanced volumetric rendering techniques.'}],\n",
       "  'courses_taught': [],\n",
       "  'clubs_and_community': [{'name': 'ACM PESU-ECC',\n",
       "    'role': 'Active member',\n",
       "    'description': 'Contributing to the organization of hackathons and events, and offering mentorship and guidance to fellow peers.'},\n",
       "   {'name': 'Parallax PESU-ECC',\n",
       "    'role': 'Core member',\n",
       "    'description': 'Involved in organizing and hosting events, and mentoring peers.'},\n",
       "   {'name': 'Kalpana 2024',\n",
       "    'role': 'Runners Up',\n",
       "    'description': 'Secured second place in the Kalpana Hackathon, hosted by IEEE, by developing a blockchain-based charity platform that utilizes smart contracts.'},\n",
       "   {'name': 'DeltaTime 2024',\n",
       "    'role': '2nd Runners Up',\n",
       "    'description': 'Achieved third place in the DeltaTime 2024 Game Jam, organized by Parallax PESU.'}],\n",
       "  'achievements': [],\n",
       "  'publications': []},\n",
       " 'nith.pugazhanthi@gmail.com': {'contact_information': {'name': 'Nitheesh Pugazhanti',\n",
       "   'contact': {'phone': '6363485819',\n",
       "    'email': 'nith.pugazhanthi@gmail.com',\n",
       "    'github': 'github.com/Noth2006',\n",
       "    'linkedin': '',\n",
       "    'website': ''}},\n",
       "  'education': [{'institution': 'PES University',\n",
       "    'degree': 'Bachelor of Technology',\n",
       "    'field_of_study': 'Computer Science and Engineering',\n",
       "    'duration': '2022 – 2026',\n",
       "    'location': 'Bangalore, India',\n",
       "    'GPA': ''},\n",
       "   {'institution': 'Presidency School Bangalore East',\n",
       "    'degree': 'Grade 12',\n",
       "    'field_of_study': 'N/A',\n",
       "    'duration': '2022',\n",
       "    'location': 'Bangalore, India',\n",
       "    'GPA': ''}],\n",
       "  'experience': [],\n",
       "  'technical_skills': {'languages': ['Python',\n",
       "    'C',\n",
       "    'R',\n",
       "    'Rust',\n",
       "    'CUDA',\n",
       "    'JavaScript',\n",
       "    'HTML/CSS',\n",
       "    'ARM Assembly'],\n",
       "   'technologies': ['pandas',\n",
       "    'NumPy',\n",
       "    'Matplotlib',\n",
       "    'Pytorch',\n",
       "    'tensorflow',\n",
       "    'Git',\n",
       "    'Kaggle',\n",
       "    'Neovim',\n",
       "    'Visual Studio',\n",
       "    'PyCharm',\n",
       "    'IntelliJ',\n",
       "    'Rstudio']},\n",
       "  'projects': [{'name': 'Implementation of a Virtual Machine for LC-3 Assembly Language Execution',\n",
       "    'description': 'The VM supports the entire LC-3 instruction set, including operations such as arithmetic (ADD, AND), data movement (LD, ST), control flow (BR, JMP, JSR) and other operations (NOT, TRAP). Managed memory by implementing a 65,536 location array and an enum containing all the registers.'},\n",
       "   {'name': 'ML based Intrusion Detection Systems with NodeMCU Esp-32 and UNSW-NB15',\n",
       "    'description': 'It is a 2 level intrusion detection system, where the packet capture is performed by esp-32 micro controller. In the first level the incoming packet is matched with a database of all known malware signatures. In the second level the packets are passed on to classification ML models to detect zero-day attacks. Achieved up to 88% accuracy with feature extraction.'},\n",
       "   {'name': 'Recommendation System',\n",
       "    'description': 'Developed a recommendation system in C using weighted graphs with adjacency lists to manage product relationships. Implemented a closest match algorithm to suggest related products based on assigned weights, improving recommendation accuracy. Has a custom json parser implemented using stacks to read input files.'},\n",
       "   {'name': 'Automated Text Analysis and New quality Index using a LLM',\n",
       "    'description': 'Defined a new Quality Index formula that can be used to assess the quality of various documents for readability and cohesion. The fine-tuned LLM assesses the quality of each document and provides the final score.'}],\n",
       "  'courses_taught': [],\n",
       "  'clubs_and_community': [],\n",
       "  'achievements': [],\n",
       "  'publications': []},\n",
       " 'raghav.balakrishnan@gmail.com': {'contact_information': {'name': 'Raghav Balakrishnan',\n",
       "   'contact': {'phone': '+91 8296300963',\n",
       "    'email': 'raghav.balakrishnan@gmail.com',\n",
       "    'github': 'https://github.com/RaghavB1404',\n",
       "    'linkedin': '',\n",
       "    'website': ''}},\n",
       "  'education': [{'institution': 'PES University',\n",
       "    'degree': 'Bachelor of Technology',\n",
       "    'field_of_study': 'Computer Science',\n",
       "    'duration': '2022 - 2026',\n",
       "    'location': 'Bangalore, India',\n",
       "    'GPA': ''},\n",
       "   {'institution': 'Base PU College',\n",
       "    'degree': 'Higher Secondary School',\n",
       "    'field_of_study': '',\n",
       "    'duration': '2020 - 2022',\n",
       "    'location': 'Bangalore, India',\n",
       "    'GPA': ''}],\n",
       "  'experience': [{'company': 'Centre of Data Modelling, Analytics and Visualization, PES University',\n",
       "    'position': 'Research Intern',\n",
       "    'duration': 'Jun 2024 – Aug 2024',\n",
       "    'location': 'Bangalore, India',\n",
       "    'responsibilities': ['Engineered an advanced hybrid neural network model by combining Long Short-Term Memory (LSTM) networks with Kolmogorov Arnold Networks (KAN) for stock price forecasting.',\n",
       "     'Designed and implemented a robust data pipeline that integrates text data with numerical OHLC data to enhance predictive accuracy.',\n",
       "     'Developed and fine-tuned the hybrid model for algorithmic trading applications, resulting in improved predictive accuracy and trading strategy performance.']}],\n",
       "  'technical_skills': {'languages': ['Python', 'C'],\n",
       "   'technologies': ['TensorFlow',\n",
       "    'Keras',\n",
       "    'Pygame',\n",
       "    'OpenCV',\n",
       "    'Raspberry Pi',\n",
       "    'MongoDB',\n",
       "    'React.js',\n",
       "    'Node.js',\n",
       "    'Express.js',\n",
       "    'Pandas',\n",
       "    'Scikit-learn',\n",
       "    'Matplotlib',\n",
       "    'NumPy']},\n",
       "  'projects': [{'name': 'Autonomous Car',\n",
       "    'description': 'Designed and implemented an autonomous car using a Raspberry Pi and neural networks for navigation and decision-making.'},\n",
       "   {'name': 'Stock Portfolio Manager',\n",
       "    'description': 'Created a stock market simulator to trade and manage portfolio using MERN stack and integrated APIs for real-time data feed.'},\n",
       "   {'name': 'Productivity Note Taking Tool',\n",
       "    'description': 'Developed a note-taking tool using data structures and file system operations to enhance productivity and streamline note-taking processes.'}],\n",
       "  'courses_taught': [],\n",
       "  'clubs_and_community': [],\n",
       "  'achievements': [],\n",
       "  'publications': []},\n",
       " 'rithul1905@gmail.com': {'contact_information': {'name': 'Rithul Rakesh',\n",
       "   'contact': {'phone': '',\n",
       "    'email': 'rithul1905@gmail.com',\n",
       "    'github': 'GitHub',\n",
       "    'linkedin': 'LinkedIn',\n",
       "    'website': ''}},\n",
       "  'education': [{'institution': 'PES UNIVERSITY',\n",
       "    'degree': 'Bachelor of Technology',\n",
       "    'field_of_study': 'Computer Science Engineering',\n",
       "    'duration': 'Expected May 2026',\n",
       "    'location': 'Bangalore, Karnataka',\n",
       "    'GPA': None}],\n",
       "  'experience': [{'company': 'CENTRE OF DATA MODELLING, ANALYTICS AND VISUALIZATION, PESU',\n",
       "    'position': 'RESEARCH INTERN',\n",
       "    'duration': 'Jun 2024 – Aug 2024',\n",
       "    'location': 'Bangalore, Karnataka',\n",
       "    'responsibilities': ['Tasked with developing a high-performance algorithmic trading system for volatile market conditions, focusing on combining traditional time-series analysis with real-time market sentiment data.',\n",
       "     'Led the design and implementation of a novel hybrid neural network architecture integrating Long Short-Term Memory (LSTM) networks with Kolmogorov Arnold Networks (KAN), optimizing for non-linear pattern recognition in financial time series.',\n",
       "     'Engineered an advanced data pipeline integrating vector databases, RAG pipeline, and FinBERT for comprehensive financial data processing, combining OHLC market data with real-time sentiment analysis from over 1000+ financial news articles spanning 30 days and 2 years of historical stock data.',\n",
       "     'Achieved 30% improvement in directional prediction accuracy compared to traditional LSTM models.']}],\n",
       "  'technical_skills': {'languages': ['Python', 'C'],\n",
       "   'technologies': ['TensorFlow',\n",
       "    'PyTorch',\n",
       "    'BERT',\n",
       "    'RAG pipelines',\n",
       "    'Vector Databases',\n",
       "    'Kafka',\n",
       "    'Hadoop',\n",
       "    'Spark',\n",
       "    'AWS Cloud Services',\n",
       "    'React.js',\n",
       "    'MongoDB',\n",
       "    'MySQL']},\n",
       "  'projects': [{'name': 'MULTIMODAL EMOTION CLASSIFICATION USING TEXT AND VIDEO FEATURES',\n",
       "    'description': 'Developed a multimodal deep learning model for emotion classification, integrating BERT for textual embeddings and ResNet-50 for video frame analysis, enabling accurate sentiment prediction.'},\n",
       "   {'name': 'BENCHMARKING TRANSFORMER MODELS FOR MULTI-TASK NLP APPLICATIONS',\n",
       "    'description': 'Evaluated four state of the art transformer models; BERT, RoBERTa, BART, and GPT pipelines using Hugging Face’s Transformers library to perform advanced tasks such as summarization, text completion, question answering, and story generation.'},\n",
       "   {'name': 'DISTRIBUTED LOGGING SYSTEM',\n",
       "    'description': 'Designed and implemented a microservices-based logging architecture using Fluentd to collect logs from multiple nodes, and Apache Kafka for real-time log distribution.'}],\n",
       "  'courses_taught': [],\n",
       "  'clubs_and_community': [],\n",
       "  'achievements': [{'event': 'Academic Performance',\n",
       "    'placement': '3x recipient of Distinction and Scholarship',\n",
       "    'description': 'Awarded for top academic performance in Computer Science Engineering.'}],\n",
       "  'publications': []},\n",
       " '+919618403578': {'contact_information': {'name': 'Sreecharan Palepu',\n",
       "   'contact': {'phone': '+919618403578',\n",
       "    'email': '',\n",
       "    'github': '',\n",
       "    'linkedin': 'https://www.linkedin.com/in/sreecharan-p',\n",
       "    'website': ''}},\n",
       "  'education': [{'institution': 'PES University',\n",
       "    'degree': 'Bachelor of Technology',\n",
       "    'field_of_study': 'Computer Science and Engineering',\n",
       "    'duration': 'Present',\n",
       "    'location': 'Bangalore, India',\n",
       "    'GPA': None}],\n",
       "  'experience': [{'company': 'PES University',\n",
       "    'position': 'Research Intern',\n",
       "    'duration': 'June 2024 - Present',\n",
       "    'location': 'Bangalore, India',\n",
       "    'responsibilities': ['Applicating LLM’s and algorithmic retrieval techniques to find the research gap and finding a suitable model for a dataset.']}],\n",
       "  'technical_skills': {'languages': ['Python', 'C/C++', 'R'],\n",
       "   'technologies': ['pandas',\n",
       "    'numpy',\n",
       "    'scikit-learn',\n",
       "    'HuggingFace',\n",
       "    'NLTK',\n",
       "    'Keras',\n",
       "    'Langchain',\n",
       "    'TensorFlow',\n",
       "    'Git',\n",
       "    'MongoDB',\n",
       "    'SQL',\n",
       "    'Spacy',\n",
       "    'LlamaIndex',\n",
       "    'Pydantic']},\n",
       "  'projects': [{'name': 'Real-Time Stock Price Tracking and Analysis',\n",
       "    'description': 'Created StockWatch Pro, a Python tool for scraping real-time stock prices, creating watch lists, and analyzing stock statistics using DearPyGui.'},\n",
       "   {'name': 'LLM-Powered Multimodal Research Gap Analysis and Model Recommendation System',\n",
       "    'description': 'Developed an LLM-powered system to analyze research papers and identify research gaps. The system evaluates performance against other models and conducts comprehensive dataset analysis. It recommends suitable models for specific tasks based on the contextual information.'},\n",
       "   {'name': 'HR-Driven Semantic Metadata System for Resume Filtering, Querying, and Ranking',\n",
       "    'description': 'Developing an application to improve shortlisting efficiency by evaluating candidates comprehensively, including GitHub profiles, project assessments, and other relevant metrics.'}],\n",
       "  'courses_taught': [],\n",
       "  'clubs_and_community': [{'name': 'Qforest',\n",
       "    'role': 'Marketing & Sponsorship',\n",
       "    'description': 'Played a key role in securing sponsorships, including a partnership with Honeywell, and managed budgets and finances for club events to ensure their success.'}],\n",
       "  'achievements': [],\n",
       "  'publications': [{'title': 'LLM-Powered Multimodal Research Gap Analysis and Model Recommendation System',\n",
       "    'authors': [],\n",
       "    'journal_or_conference': 'Paper publication in progress',\n",
       "    'year': '',\n",
       "    'doi': '',\n",
       "    'abstract': ''}]}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:18.994270Z",
     "start_time": "2025-04-11T13:29:16.425777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ],
   "id": "72e0a0646aadc94d",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:19.009642Z",
     "start_time": "2025-04-11T13:29:18.997022Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d0b2d5f41cd04fe8",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:22.974950Z",
     "start_time": "2025-04-11T13:29:19.012642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_chroma import Chroma\n",
    "vector_store_contact_information = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"contact_information\",\n",
    "    persist_directory=\"./chroma_langchain_db_1\",\n",
    ")\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "vector_store_education = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"education\",\n",
    "    persist_directory=\"./chroma_langchain_db_1\",\n",
    ")\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "vector_store_experience = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"experience\",\n",
    "    persist_directory=\"./chroma_langchain_db_1\",\n",
    ")\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "vector_store_technical_skills = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"technical_skills\",\n",
    "    persist_directory=\"./chroma_langchain_db_1\",\n",
    ")\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "vector_store_projects = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"projects\",\n",
    "    persist_directory=\"./chroma_langchain_db_1\",\n",
    ")\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "vector_store_clubs_and_communities = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"clubs_and_communities\",\n",
    "    persist_directory=\"./chroma_langchain_db_1\",\n",
    ")\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "vector_store_achievements= Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"achievements\",\n",
    "    persist_directory=\"./chroma_langchain_db_1\",\n",
    ")\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "vector_store_publications = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"publications\",\n",
    "    persist_directory=\"./chroma_langchain_db_1\",\n",
    ")"
   ],
   "id": "f597ccef84d7fc58",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an assistant that normalizes the given JSON input into the following structured format:\n",
    "            {{\n",
    "              \"contact_information\": {{\n",
    "                \"name\": \"<Full Name>\",\n",
    "                \"contact\": {{\n",
    "                  \"phone\": \"<Phone Number>\",\n",
    "                  \"email\": \"<Email Address>\",\n",
    "                  \"github\": \"<GitHub Profile URL>\",\n",
    "                  \"linkedin\": \"<LinkedIn Profile URL>\",\n",
    "                  \"website\": \"<Personal Website or Portfolio URL>\"\n",
    "                }}\n",
    "              }},\n",
    "              \"education\": [\n",
    "                {{\n",
    "                  \"institution\": \"<University or College Name>\",\n",
    "                  \"degree\": \"<Degree Name>\",\n",
    "                  \"field_of_study\": \"<Field of Study>\",\n",
    "                  \"duration\": \"<Start Year - End Year or Present>\",\n",
    "                  \"location\": \"<City, Country>\",\n",
    "                  \"GPA\":<GPA of the candidate>\n",
    "                }}\n",
    "              ],\n",
    "              \"experience\": [\n",
    "                {{\n",
    "                  \"company\": \"<Company Name>\",\n",
    "                  \"position\": \"<Job Title>\",\n",
    "                  \"duration\": \"<Start Date - End Date or Present>\",\n",
    "                  \"location\": \"<City, Country>\",\n",
    "                  \"responsibilities\": [\n",
    "                    \"<Responsibility or achievement 1>\",\n",
    "                    \"<Responsibility or achievement 2>\",\n",
    "                    \"<Responsibility or achievement 3>\"\n",
    "                  ]\n",
    "                }}\n",
    "              ],\n",
    "              \"technical_skills\": {{\n",
    "                \"languages\": [\"<Programming Language 1>\", \"<Programming Language 2>\", \"...\"],\n",
    "                \"technologies\": [\"<Technology 1>\", \"<Technology 2>\", \"...\"]\n",
    "              }},\n",
    "              \"projects\": [\n",
    "                {{\n",
    "                  \"name\": \"<Project Name>\",\n",
    "                  \"description\": \"<Brief description of the project highlighting its functionality and purpose>\"\n",
    "                }}\n",
    "              ],\n",
    "              \"courses_taught\": [\n",
    "                {{\n",
    "                  \"title\": \"<Course Name>\",\n",
    "                  \"duration\": \"<Start Date - End Date>\",\n",
    "                  \"description\": \"<Brief description of the course and topics covered>\"\n",
    "                }}\n",
    "              ],\n",
    "              \"clubs_and_community\": [\n",
    "                {{\n",
    "                  \"name\": \"<Club or Organization Name>\",\n",
    "                  \"role\": \"<Role in the Organization>\",\n",
    "                  \"description\": \"<Contributions and activities>\"\n",
    "                }}\n",
    "              ],\n",
    "              \"achievements\": [\n",
    "                {{\n",
    "                  \"event\": \"<Event or Competition Name>\",\n",
    "                  \"placement\": \"<Rank or Award>\",\n",
    "                  \"description\": \"<Brief details on the competition and accomplishment>\"\n",
    "                }}\n",
    "              ],\n",
    "              \"publications\": [\n",
    "                {{\n",
    "                  \"title\": \"<Publication Title>\",\n",
    "                  \"authors\": [\"<Author 1>\", \"<Author 2>\", \"...\"],\n",
    "                  \"journal_or_conference\": \"<Journal or Conference Name>\",\n",
    "                  \"year\": \"<Year of Publication>\",\n",
    "                  \"doi\": \"<DOI or URL>\",\n",
    "                  \"abstract\": \"<Brief summary of the publication>\"\n",
    "                }}\n",
    "              ]\n",
    "            }}\n",
    "            Only return JSON output in this exact format, nothing else.\"\"\"\n",
    "        ),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n"
   ],
   "id": "9f5bd8de4d17480"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:23.038534Z",
     "start_time": "2025-04-11T13:29:22.978376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "contact_information = {}\n",
    "education = {}\n",
    "experience = {}\n",
    "technical_skills = {}\n",
    "projects = {}\n",
    "clubs_and_community = {}\n",
    "achievements = {}\n",
    "publications = {}"
   ],
   "id": "cd1b98587e5ebe5f",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:23.082890Z",
     "start_time": "2025-04-11T13:29:23.048379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def decoupling_component(resultant_metadata_combined):\n",
    "    for i, k in resultant_metadata_combined.items():\n",
    "        contact_information[i] = k.get(\"contact_information\")\n",
    "        education[i] = k.get(\"education\")\n",
    "        experience[i] = k.get(\"experience\")\n",
    "        technical_skills[i] = k.get(\"technical_skills\")\n",
    "        projects[i] = k.get(\"projects\")\n",
    "        clubs_and_community[i] = k.get(\"clubs_and_community\")\n",
    "        achievements[i] = k.get(\"achievements\")\n",
    "        publications[i] = k.get(\"publications\")"
   ],
   "id": "7eea11c87aa0aa12",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:23.098175Z",
     "start_time": "2025-04-11T13:29:23.085722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, k in contact_information.items():\n",
    "    print(i)"
   ],
   "id": "8e627a080691982f",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:23.113291Z",
     "start_time": "2025-04-11T13:29:23.102503Z"
    }
   },
   "cell_type": "code",
   "source": "decoupling_component(resultant_metadata_combined=resultant_metadata_combined)",
   "id": "7b1837dfdff3ba36",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:23.144085Z",
     "start_time": "2025-04-11T13:29:23.116004Z"
    }
   },
   "cell_type": "code",
   "source": "education",
   "id": "a1e87d6590a965c7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nevillejs24@gmail.com': [{'institution': 'PES University',\n",
       "   'degree': 'Bachelor of Technology',\n",
       "   'field_of_study': 'Computer Science and Engineering',\n",
       "   'duration': '2022 - Present',\n",
       "   'location': 'Bangalore, India',\n",
       "   'GPA': ''}],\n",
       " 'nith.pugazhanthi@gmail.com': [{'institution': 'PES University',\n",
       "   'degree': 'Bachelor of Technology',\n",
       "   'field_of_study': 'Computer Science and Engineering',\n",
       "   'duration': '2022 – 2026',\n",
       "   'location': 'Bangalore, India',\n",
       "   'GPA': ''},\n",
       "  {'institution': 'Presidency School Bangalore East',\n",
       "   'degree': 'Grade 12',\n",
       "   'field_of_study': 'N/A',\n",
       "   'duration': '2022',\n",
       "   'location': 'Bangalore, India',\n",
       "   'GPA': ''}],\n",
       " 'raghav.balakrishnan@gmail.com': [{'institution': 'PES University',\n",
       "   'degree': 'Bachelor of Technology',\n",
       "   'field_of_study': 'Computer Science',\n",
       "   'duration': '2022 - 2026',\n",
       "   'location': 'Bangalore, India',\n",
       "   'GPA': ''},\n",
       "  {'institution': 'Base PU College',\n",
       "   'degree': 'Higher Secondary School',\n",
       "   'field_of_study': '',\n",
       "   'duration': '2020 - 2022',\n",
       "   'location': 'Bangalore, India',\n",
       "   'GPA': ''}],\n",
       " 'rithul1905@gmail.com': [{'institution': 'PES UNIVERSITY',\n",
       "   'degree': 'Bachelor of Technology',\n",
       "   'field_of_study': 'Computer Science Engineering',\n",
       "   'duration': 'Expected May 2026',\n",
       "   'location': 'Bangalore, Karnataka',\n",
       "   'GPA': None}],\n",
       " '+919618403578': [{'institution': 'PES University',\n",
       "   'degree': 'Bachelor of Technology',\n",
       "   'field_of_study': 'Computer Science and Engineering',\n",
       "   'duration': 'Present',\n",
       "   'location': 'Bangalore, India',\n",
       "   'GPA': None}]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:23.174861Z",
     "start_time": "2025-04-11T13:29:23.148089Z"
    }
   },
   "cell_type": "code",
   "source": "contact_information",
   "id": "a8345f933ab71ef8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nevillejs24@gmail.com': {'name': 'Neville Joseph Sabu',\n",
       "  'contact': {'phone': '+91-9747953669',\n",
       "   'email': 'nevillejs24@gmail.com',\n",
       "   'github': 'https://github.com/neb0lle',\n",
       "   'linkedin': '',\n",
       "   'website': ''}},\n",
       " 'nith.pugazhanthi@gmail.com': {'name': 'Nitheesh Pugazhanti',\n",
       "  'contact': {'phone': '6363485819',\n",
       "   'email': 'nith.pugazhanthi@gmail.com',\n",
       "   'github': 'github.com/Noth2006',\n",
       "   'linkedin': '',\n",
       "   'website': ''}},\n",
       " 'raghav.balakrishnan@gmail.com': {'name': 'Raghav Balakrishnan',\n",
       "  'contact': {'phone': '+91 8296300963',\n",
       "   'email': 'raghav.balakrishnan@gmail.com',\n",
       "   'github': 'https://github.com/RaghavB1404',\n",
       "   'linkedin': '',\n",
       "   'website': ''}},\n",
       " 'rithul1905@gmail.com': {'name': 'Rithul Rakesh',\n",
       "  'contact': {'phone': '',\n",
       "   'email': 'rithul1905@gmail.com',\n",
       "   'github': 'GitHub',\n",
       "   'linkedin': 'LinkedIn',\n",
       "   'website': ''}},\n",
       " '+919618403578': {'name': 'Sreecharan Palepu',\n",
       "  'contact': {'phone': '+919618403578',\n",
       "   'email': '',\n",
       "   'github': '',\n",
       "   'linkedin': 'https://www.linkedin.com/in/sreecharan-p',\n",
       "   'website': ''}}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:23.190442Z",
     "start_time": "2025-04-11T13:29:23.177937Z"
    }
   },
   "cell_type": "code",
   "source": "publications",
   "id": "5497940926800fd8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nevillejs24@gmail.com': [],\n",
       " 'nith.pugazhanthi@gmail.com': [],\n",
       " 'raghav.balakrishnan@gmail.com': [],\n",
       " 'rithul1905@gmail.com': [],\n",
       " '+919618403578': [{'title': 'LLM-Powered Multimodal Research Gap Analysis and Model Recommendation System',\n",
       "   'authors': [],\n",
       "   'journal_or_conference': 'Paper publication in progress',\n",
       "   'year': '',\n",
       "   'doi': '',\n",
       "   'abstract': ''}]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:23.206253Z",
     "start_time": "2025-04-11T13:29:23.195534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from uuid import uuid4\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def load_documents(json_file):\n",
    "    docs = [Document(page_content=i + str(k), metadata={\"identifier\": i}) for i, k in json_file.items()]\n",
    "    uuids_docs = [str(uuid4()) for _ in range(len(docs))]\n",
    "    return docs, uuids_docs"
   ],
   "id": "e11c94ef282b1933",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:23.237299Z",
     "start_time": "2025-04-11T13:29:23.209293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "docs_contact_information, uuids_contact_information = load_documents(contact_information)\n",
    "docs_education, uuids_education = load_documents(education)\n",
    "docs_experience, uuids_experience = load_documents(experience)\n",
    "docs_technical_skills, uuids_technical_skills = load_documents(technical_skills)\n",
    "docs_projects, uuids_projects = load_documents(projects)\n",
    "docs_clubs_and_community, uuids_clubs_and_community = load_documents(clubs_and_community)\n",
    "docs_achievements, uuids_achievements = load_documents(achievements)\n",
    "docs_publications, uuids_publications = load_documents(publications)"
   ],
   "id": "75b6fb716e50c146",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:23.266949Z",
     "start_time": "2025-04-11T13:29:23.241304Z"
    }
   },
   "cell_type": "code",
   "source": "docs_projects",
   "id": "a0f89c3e46a44136",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'identifier': 'nevillejs24@gmail.com'}, page_content=\"nevillejs24@gmail.com[{'name': 'wog', 'description': 'A compact web-based 3D rendering engine built with WebGL, designed to render complex simulations and dynamic effects.'}, {'name': 'daBlob', 'description': 'A real-time simulation of Physarum slime using cellular automata, exploring and visualizing growth patterns and behaviors.'}, {'name': 'raycst', 'description': 'Raymarching implemented in OpenGL, showcasing advanced volumetric rendering techniques.'}]\"),\n",
       " Document(metadata={'identifier': 'nith.pugazhanthi@gmail.com'}, page_content=\"nith.pugazhanthi@gmail.com[{'name': 'Implementation of a Virtual Machine for LC-3 Assembly Language Execution', 'description': 'The VM supports the entire LC-3 instruction set, including operations such as arithmetic (ADD, AND), data movement (LD, ST), control flow (BR, JMP, JSR) and other operations (NOT, TRAP). Managed memory by implementing a 65,536 location array and an enum containing all the registers.'}, {'name': 'ML based Intrusion Detection Systems with NodeMCU Esp-32 and UNSW-NB15', 'description': 'It is a 2 level intrusion detection system, where the packet capture is performed by esp-32 micro controller. In the first level the incoming packet is matched with a database of all known malware signatures. In the second level the packets are passed on to classification ML models to detect zero-day attacks. Achieved up to 88% accuracy with feature extraction.'}, {'name': 'Recommendation System', 'description': 'Developed a recommendation system in C using weighted graphs with adjacency lists to manage product relationships. Implemented a closest match algorithm to suggest related products based on assigned weights, improving recommendation accuracy. Has a custom json parser implemented using stacks to read input files.'}, {'name': 'Automated Text Analysis and New quality Index using a LLM', 'description': 'Defined a new Quality Index formula that can be used to assess the quality of various documents for readability and cohesion. The fine-tuned LLM assesses the quality of each document and provides the final score.'}]\"),\n",
       " Document(metadata={'identifier': 'raghav.balakrishnan@gmail.com'}, page_content=\"raghav.balakrishnan@gmail.com[{'name': 'Autonomous Car', 'description': 'Designed and implemented an autonomous car using a Raspberry Pi and neural networks for navigation and decision-making.'}, {'name': 'Stock Portfolio Manager', 'description': 'Created a stock market simulator to trade and manage portfolio using MERN stack and integrated APIs for real-time data feed.'}, {'name': 'Productivity Note Taking Tool', 'description': 'Developed a note-taking tool using data structures and file system operations to enhance productivity and streamline note-taking processes.'}]\"),\n",
       " Document(metadata={'identifier': 'rithul1905@gmail.com'}, page_content=\"rithul1905@gmail.com[{'name': 'MULTIMODAL EMOTION CLASSIFICATION USING TEXT AND VIDEO FEATURES', 'description': 'Developed a multimodal deep learning model for emotion classification, integrating BERT for textual embeddings and ResNet-50 for video frame analysis, enabling accurate sentiment prediction.'}, {'name': 'BENCHMARKING TRANSFORMER MODELS FOR MULTI-TASK NLP APPLICATIONS', 'description': 'Evaluated four state of the art transformer models; BERT, RoBERTa, BART, and GPT pipelines using Hugging Face’s Transformers library to perform advanced tasks such as summarization, text completion, question answering, and story generation.'}, {'name': 'DISTRIBUTED LOGGING SYSTEM', 'description': 'Designed and implemented a microservices-based logging architecture using Fluentd to collect logs from multiple nodes, and Apache Kafka for real-time log distribution.'}]\"),\n",
       " Document(metadata={'identifier': '+919618403578'}, page_content=\"+919618403578[{'name': 'Real-Time Stock Price Tracking and Analysis', 'description': 'Created StockWatch Pro, a Python tool for scraping real-time stock prices, creating watch lists, and analyzing stock statistics using DearPyGui.'}, {'name': 'LLM-Powered Multimodal Research Gap Analysis and Model Recommendation System', 'description': 'Developed an LLM-powered system to analyze research papers and identify research gaps. The system evaluates performance against other models and conducts comprehensive dataset analysis. It recommends suitable models for specific tasks based on the contextual information.'}, {'name': 'HR-Driven Semantic Metadata System for Resume Filtering, Querying, and Ranking', 'description': 'Developing an application to improve shortlisting efficiency by evaluating candidates comprehensively, including GitHub profiles, project assessments, and other relevant metrics.'}]\")]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:25.741059Z",
     "start_time": "2025-04-11T13:29:23.270517Z"
    }
   },
   "cell_type": "code",
   "source": "vector_store_contact_information.add_documents(documents=docs_contact_information, ids=uuids_contact_information)",
   "id": "9c5aaafe00776808",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['761da51f-e1a8-48df-be69-44ada1e61566',\n",
       " '8c2725ed-7b76-45f9-a6fb-065ee43e43d5',\n",
       " 'fb4deee7-c1d2-4614-84da-5b911b3f14fd',\n",
       " 'c8d9177a-5add-4e29-88e1-64bda4dd3430',\n",
       " 'f6a412e1-55c2-4a3b-a6f1-163b31ad5364']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:27.387518Z",
     "start_time": "2025-04-11T13:29:25.745060Z"
    }
   },
   "cell_type": "code",
   "source": "vector_store_education.add_documents(documents=docs_education, ids=uuids_education)",
   "id": "ed1c12697d7d51ab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['274a2c96-aecb-4631-93d1-919fb9a0a79b',\n",
       " '3ac9cd58-2207-4927-b032-d16fabfbdd37',\n",
       " 'e0b40ff1-26ff-4da1-b557-3a0edf9348d8',\n",
       " '58bec4bc-a105-4377-b893-e1d68019d9eb',\n",
       " '96dd0a86-ca0d-4e00-a8b2-f371a76d5b22']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:28.788931Z",
     "start_time": "2025-04-11T13:29:27.390559Z"
    }
   },
   "cell_type": "code",
   "source": "vector_store_experience.add_documents(documents=docs_experience, ids=uuids_experience)",
   "id": "ee361eb20e3f7893",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3c069994-a11a-448b-a7b7-c5b4f558932d',\n",
       " '93d4a556-b93b-4a6e-8ade-8fc62fe49b84',\n",
       " '0f433d5a-c180-4a8a-81bc-e71f828e9b1b',\n",
       " '9149d7d3-6d19-42ea-ae57-e30c7cc44783',\n",
       " '91536886-95ce-48f8-9e2a-69cab24361f4']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:30.564809Z",
     "start_time": "2025-04-11T13:29:28.792299Z"
    }
   },
   "cell_type": "code",
   "source": "vector_store_technical_skills.add_documents(documents=docs_technical_skills, ids=uuids_technical_skills)",
   "id": "7f0d45b7a1d7de11",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['21a9a451-cb22-40b9-b418-b2a5f82a09e4',\n",
       " '2d98daf7-82de-4c4c-b131-f81fae2fa566',\n",
       " '328a6a3f-ccb7-45bc-a647-c9db69e53d7f',\n",
       " '920da540-f28c-492a-a7d2-20d930922b29',\n",
       " '7c21155f-434e-411c-b0ec-d02790a9d504']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:32.276319Z",
     "start_time": "2025-04-11T13:29:30.567809Z"
    }
   },
   "cell_type": "code",
   "source": "vector_store_projects.add_documents(documents=docs_projects, ids=uuids_projects)",
   "id": "8544525d45715b4b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5a5f5d44-1d2b-45ff-955e-5610b2256d8b',\n",
       " '024fef59-450e-4bbc-bcdc-2d17b93ac589',\n",
       " 'dd7c5625-4041-40cc-a0d1-e6b99664c830',\n",
       " '955b0e87-8fca-4f0e-b59d-e517741e3ed0',\n",
       " '67f1a76f-a90d-442a-9086-e53c7af1c6e2']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:33.568070Z",
     "start_time": "2025-04-11T13:29:32.280623Z"
    }
   },
   "cell_type": "code",
   "source": "vector_store_clubs_and_communities.add_documents(documents=docs_clubs_and_community, ids=uuids_clubs_and_community)",
   "id": "80173ac7b69b45b6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['159ba8cd-71a7-45a3-bf74-6ff82bb1582d',\n",
       " 'cb0bab9d-280e-44de-a270-681eeee10404',\n",
       " '612613f7-5463-4642-b88f-24df9f72a510',\n",
       " '54c98c90-105e-496b-8d7a-7b66052185c6',\n",
       " '4315b8df-739c-4ff4-b3f9-d3593d5317f4']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:34.825829Z",
     "start_time": "2025-04-11T13:29:33.571407Z"
    }
   },
   "cell_type": "code",
   "source": "vector_store_achievements.add_documents(documents=docs_achievements, ids=uuids_achievements)",
   "id": "98362c2f3b8c4e97",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['92859d36-0b99-4a15-b0cf-085f6747d459',\n",
       " '984fb17d-d567-41ab-a89d-c5d82a893f4a',\n",
       " '79cae603-8b35-4396-acb0-c936910f778f',\n",
       " '425e3099-4e89-4759-88a8-dccd33ded8cc',\n",
       " '5631c210-a0e4-4ef6-8d6a-a5a4238b309e']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:29:36.207331Z",
     "start_time": "2025-04-11T13:29:34.830194Z"
    }
   },
   "cell_type": "code",
   "source": "vector_store_publications.add_documents(documents=docs_publications, ids=uuids_publications)",
   "id": "35c216e26adc035b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4c8283f8-5ec0-441d-8fbc-8a4a3cd59e8e',\n",
       " '6bd78491-fde5-4671-b0de-49662abfa628',\n",
       " 'c033f3e9-7e8b-4cbf-946e-17c2315b564c',\n",
       " '398470bc-8fb6-456e-8da9-d7a8e8ada76d',\n",
       " 'b9e09752-bc66-413d-9de3-383541b3cb93']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:07.851674Z",
     "start_time": "2025-04-11T13:29:36.219860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from pydantic_ai import Agent, RunContext, Tool\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "from pydantic_ai.providers.openai import OpenAIProvider\n",
    "\n",
    "@dataclass\n",
    "class MyDeps:\n",
    "    file_path: str\n",
    "\n",
    "system_prompt = \"\"\"\\\n",
    "You are a Job Description Summarizer. Your task is to:\n",
    "1. Extract key elements from job descriptions\n",
    "2. Identify required skills, qualifications, and experience\n",
    "3. Highlight main responsibilities\n",
    "4. Present the summary in a clear, organized format\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# def parse_jd(file_path: str) -> str:\n",
    "#     try:\n",
    "#         from llama_parse import LlamaParse\n",
    "#         parser = LlamaParse(\n",
    "#             parsing_instruction=\"Extract key job details including skills, experience, qualifications, and responsibilities\",\n",
    "#             result_type=\"markdown\"\n",
    "#         )\n",
    "#         parsed_data = parser.load_data(file_path)\n",
    "#         if not parsed_data or len(parsed_data) == 0:\n",
    "#             return \"Error: No content could be parsed from the file\"\n",
    "#         return \"\\n\".join(parsed_data[0].text.split(\"\\n\"))    \n",
    "#     except Exception as e:\n",
    "#         return f\"Error parsing file: {str(e)}\"\n",
    "\n",
    "def parse_jd(file_path: str) -> dict:\n",
    "    try:\n",
    "        from llama_parse import LlamaParse\n",
    "        parser = LlamaParse(\n",
    "            parsing_instruction=\"Extract key job details including skills, experience, qualifications, and responsibilities\",\n",
    "            result_type=\"markdown\"\n",
    "        )\n",
    "        parsed_data = parser.load_data(file_path)\n",
    "        if not parsed_data or len(parsed_data) == 0:\n",
    "            return {\"jd_summary\": \"Error: No content could be parsed from the file\"}\n",
    "        summary = \"\\n\".join(parsed_data[0].text.split(\"\\n\"))\n",
    "        return {\"jd_summary\": summary}    \n",
    "    except Exception as e:\n",
    "        return {\"jd_summary\": f\"Error parsing file: {str(e)}\"}\n",
    "    \n",
    "def get_file_path(ctx: RunContext[MyDeps]) -> str:\n",
    "    return ctx.deps.file_path\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "def generate_resume_queries(jd_summary: str) -> str:\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \n",
    " \"\"\"You are a Resume Matcher Assistant. Your task is to take the summarized job description input and generate structured queries for each section of a candidate's resume, as per the JSON schema format below.\n",
    "Only include a section if it's clearly mentioned or implied in the JD.\n",
    "Respond ONLY in valid JSON like this:\n",
    "{{\n",
    "  \"education\": \"<What kind of academic background or GPA is expected>\",\n",
    "  \"experience\": \"<Experience requirements including number of years, domains, or companies>\",\n",
    "  \"technical_skills\": \"<Specific tools, libraries, languages, etc. mentioned in the JD>\",\n",
    "  \"projects\": \"<Project expectations - e.g., worked on GenAI, LLMs, etc.>\",\n",
    "  \"courses_taught\": \"<If teaching or mentoring experience is required>\",\n",
    "  \"clubs_and_community\": \"<If leadership or social initiatives are relevant>\",\n",
    "  \"achievements\": \"<Any awards, competitions, scholarships mentioned>\",\n",
    "  \"publications\": \"<Any paper publishing requirements>\"\n",
    "}}\n",
    "Do not make things up. Just output the JSON strictly based on the summarized JD.\n",
    "\"\"\")\n",
    ",\n",
    "    (\"human\", \"{input}\")\n",
    "    ])\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"input\": jd_summary})\n",
    "    return response.content\n",
    "\n",
    "model = OpenAIModel(\n",
    "    'gpt-3.5-turbo',\n",
    "    provider=OpenAIProvider(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    ")\n",
    "\n",
    "jd_agent = Agent(\n",
    "    model=model,\n",
    "    deps_type=MyDeps,\n",
    "    tools=[\n",
    "        Tool(parse_jd, takes_ctx=False),\n",
    "        Tool(get_file_path, takes_ctx=True),\n",
    "        Tool(generate_resume_queries, takes_ctx=False)\n",
    "    ],\n",
    "    system_prompt=system_prompt\n",
    ")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    file_path = r\"C:\\Users\\sreec\\Downloads\\Data_Scientist_Job_Description.pdf\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "    else:\n",
    "        deps = MyDeps(file_path=file_path)\n",
    "        result = jd_agent.run_sync(\n",
    "            \"Please summarize this job description, and after that do generate the queries according to the format given\", \n",
    "            deps=deps\n",
    "        )\n",
    "        print(result.data)"
   ],
   "id": "15cd1b8fc57dd00a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have generated the resume queries based on the job description for a Data Scientist position. Here is the JSON response:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"education\": \"A degree in Computer Science, Statistics, Mathematics, or a related discipline.\",\n",
      "  \"experience\": \"Previous experience in data science or a related field is typically required (specific years of experience may vary based on seniority).\",\n",
      "  \"technical_skills\": \"Proficiency in data extraction, cleaning, and analysis; experience with machine learning algorithms and model deployment; familiarity with ETL processes and A/B testing methodologies.\"\n",
      "}\n",
      "``` \n",
      "\n",
      "These queries can be used to tailor your resume to the requirements of the Data Scientist job described in the job description.\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:08.270380Z",
     "start_time": "2025-04-11T13:30:07.894781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "# retriever = vector_store_projects.as_retriever(search_type=\"similarity\")\n",
    "# retrieved_docs = retriever.invoke(\"Get me the email of a person names Neville\")\n",
    "# \n",
    "# context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "# \n",
    "# reasoning_prompt = ChatPromptTemplate.from_template(\n",
    "#     \"Given the following context:\\n{context}\\n\\n\"\n",
    "#     \"Decide how many documents to use to best answer the question.\"\n",
    "# )\n",
    "# \n",
    "# llm_chain = reasoning_prompt | llm\n",
    "# final_docs = llm_chain.invoke({\"context\": context})\n",
    "# retrieved_docs"
   ],
   "id": "f4c08cac4baa5e75",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:08.317101Z",
     "start_time": "2025-04-11T13:30:08.275520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "from typing import Literal, Optional, Tuple\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "class SubQuery(BaseModel):\n",
    "    sub_query: str = Field(\n",
    "        description=\"A very specific query against the database.\",\n",
    "    )"
   ],
   "id": "b123d9bfb31333a3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sreec\\anaconda3\\envs\\HR_METADATA\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3526: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:11.470494Z",
     "start_time": "2025-04-11T13:30:08.321576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.output_parsers import PydanticToolsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "system = \"\"\"\n",
    "You are an expert at converting structured job requirements into clear, directive sub-queries for database retrieval.\n",
    "You will be given structured input containing labeled sections (such as education, experience, technical_skills).\n",
    "Each section outlines a specific need in a candidate profile.\n",
    "Your task is to convert each section into one or more sub-queries phrased as specific needs — for example, \"I need a candidate who...\", \"Looking for someone with...\", etc.\n",
    "Be as specific as the input allows — include areas like domain (e.g. math, computer science), tools (e.g. ETL, A/B testing), and required experience levels.\n",
    "Do NOT rewrite or generalize the sections into vague job descriptions — instead, reframe them as concrete requirements.\n",
    "Preserve acronyms and keywords exactly as they appear.\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "llm_openai = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "llm_with_tools = llm_openai.bind_tools([SubQuery])\n",
    "parser = PydanticToolsParser(tools=[SubQuery])\n",
    "query_analyser = prompt | llm_with_tools | parser"
   ],
   "id": "753b6e8e42d591a6",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:14.124991Z",
     "start_time": "2025-04-11T13:30:11.473496Z"
    }
   },
   "cell_type": "code",
   "source": "subqueries = query_analyser.invoke({\"question\":result.data})",
   "id": "4bd20d186d987aea",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:14.140507Z",
     "start_time": "2025-04-11T13:30:14.127989Z"
    }
   },
   "cell_type": "code",
   "source": "subqueries",
   "id": "10f6db372c01b089",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SubQuery(sub_query='I need a candidate with a degree in Computer Science, Statistics, Mathematics, or a related discipline.'),\n",
       " SubQuery(sub_query='Looking for someone with previous experience in data science or a related field; specific years of experience may vary based on seniority.'),\n",
       " SubQuery(sub_query='Seeking proficiency in data extraction, cleaning, and analysis; experience with machine learning algorithms and model deployment; familiarity with ETL processes and A/B testing methodologies.')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:14.156026Z",
     "start_time": "2025-04-11T13:30:14.144507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_questions(subqueries_list):\n",
    "    return [query_1.sub_query for query_1 in subqueries_list]"
   ],
   "id": "80a32f116c9f9c51",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:14.171546Z",
     "start_time": "2025-04-11T13:30:14.159027Z"
    }
   },
   "cell_type": "code",
   "source": "list_of_sub_queries = extract_questions(subqueries)",
   "id": "45d233f7820c8838",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:14.187065Z",
     "start_time": "2025-04-11T13:30:14.177056Z"
    }
   },
   "cell_type": "code",
   "source": "print(list_of_sub_queries)",
   "id": "2cc20ce9d7dddc63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I need a candidate with a degree in Computer Science, Statistics, Mathematics, or a related discipline.', 'Looking for someone with previous experience in data science or a related field; specific years of experience may vary based on seniority.', 'Seeking proficiency in data extraction, cleaning, and analysis; experience with machine learning algorithms and model deployment; familiarity with ETL processes and A/B testing methodologies.']\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:14.202586Z",
     "start_time": "2025-04-11T13:30:14.190068Z"
    }
   },
   "cell_type": "code",
   "source": "list_of_sub_queries = ['Looking for someone with previous experience in Game Development or Graphic designing Specific years of experience may vary based on seniority.']",
   "id": "6aa131bc61cf1590",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:14.218103Z",
     "start_time": "2025-04-11T13:30:14.205587Z"
    }
   },
   "cell_type": "code",
   "source": "list_of_sub_queries",
   "id": "eb278c0b22a74e05",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Looking for someone with previous experience in Game Development or Graphic designing Specific years of experience may vary based on seniority.']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:14.233629Z",
     "start_time": "2025-04-11T13:30:14.221102Z"
    }
   },
   "cell_type": "code",
   "source": "docs_education",
   "id": "c13db430b4f57598",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'identifier': 'nevillejs24@gmail.com'}, page_content=\"nevillejs24@gmail.com[{'institution': 'PES University', 'degree': 'Bachelor of Technology', 'field_of_study': 'Computer Science and Engineering', 'duration': '2022 - Present', 'location': 'Bangalore, India', 'GPA': ''}]\"),\n",
       " Document(metadata={'identifier': 'nith.pugazhanthi@gmail.com'}, page_content=\"nith.pugazhanthi@gmail.com[{'institution': 'PES University', 'degree': 'Bachelor of Technology', 'field_of_study': 'Computer Science and Engineering', 'duration': '2022 – 2026', 'location': 'Bangalore, India', 'GPA': ''}, {'institution': 'Presidency School Bangalore East', 'degree': 'Grade 12', 'field_of_study': 'N/A', 'duration': '2022', 'location': 'Bangalore, India', 'GPA': ''}]\"),\n",
       " Document(metadata={'identifier': 'raghav.balakrishnan@gmail.com'}, page_content=\"raghav.balakrishnan@gmail.com[{'institution': 'PES University', 'degree': 'Bachelor of Technology', 'field_of_study': 'Computer Science', 'duration': '2022 - 2026', 'location': 'Bangalore, India', 'GPA': ''}, {'institution': 'Base PU College', 'degree': 'Higher Secondary School', 'field_of_study': '', 'duration': '2020 - 2022', 'location': 'Bangalore, India', 'GPA': ''}]\"),\n",
       " Document(metadata={'identifier': 'rithul1905@gmail.com'}, page_content=\"rithul1905@gmail.com[{'institution': 'PES UNIVERSITY', 'degree': 'Bachelor of Technology', 'field_of_study': 'Computer Science Engineering', 'duration': 'Expected May 2026', 'location': 'Bangalore, Karnataka', 'GPA': None}]\"),\n",
       " Document(metadata={'identifier': '+919618403578'}, page_content=\"+919618403578[{'institution': 'PES University', 'degree': 'Bachelor of Technology', 'field_of_study': 'Computer Science and Engineering', 'duration': 'Present', 'location': 'Bangalore, India', 'GPA': None}]\")]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4bad61ca15b92c48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:14.249687Z",
     "start_time": "2025-04-11T13:30:14.236628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain.chains import LLMChain\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# \n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# \n",
    "# def retrieve_for_subqueries(subqueries, retriever):\n",
    "#     all_docs = []\n",
    "#     for query in subqueries:\n",
    "#         results = retriever.invoke(query)\n",
    "#         all_docs.extend(results)\n",
    "#     return all_docs\n",
    "# \n",
    "# # Step 3: Reasoning Agent to Filter Retrieved Results\n",
    "# reasoning_prompt = ChatPromptTemplate.from_template(\n",
    "#     \"You are an intelligent assistant. Given the original user question:\\n\"\n",
    "#     \"{user_query}\\n\\n\"\n",
    "#     \"The question was decomposed into the following subqueries:\\n\"\n",
    "#     \"{subqueries}\\n\\n\"\n",
    "#     \"Here are the retrieved results:\\n\\n\"\n",
    "#     \"{context}\\n\\n\"\n",
    "#     \"Based on the above, extract only the most relevant information and provide a final, concise answer, and format the answer properly in a json format before giving it out.\"\n",
    "# )\n",
    "# \n",
    "# def reasoning_agent(user_query, subqueries, docs, llm):\n",
    "#     subquery_text = \"\\n\".join([f\"- {sq}\" for sq in subqueries])\n",
    "#     context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "#     \n",
    "#     reasoning_chain = reasoning_prompt | llm | StrOutputParser()\n",
    "#     \n",
    "#     return reasoning_chain.invoke({\n",
    "#         \"user_query\": user_query,\n",
    "#         \"subqueries\": subquery_text,\n",
    "#         \"context\": context\n",
    "#     })\n",
    "# \n",
    "# def retrieval_chain(user_query, retriever, llm):\n",
    "#     subqueries = list_of_sub_queries\n",
    "#     retrieved_docs = retrieve_for_subqueries(subqueries, retriever)\n",
    "#     final_answer = reasoning_agent(user_query, subqueries, retrieved_docs, llm)\n",
    "#     return final_answer"
   ],
   "id": "ccbd5d45fa1c9e63",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:14.264696Z",
     "start_time": "2025-04-11T13:30:14.253698Z"
    }
   },
   "cell_type": "code",
   "source": "# query=\"Get me just the email of the candidates who have done some projects in the LLMs or Ge nAi Space\"",
   "id": "d418fa588980dab7",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:14.295756Z",
     "start_time": "2025-04-11T13:30:14.268698Z"
    }
   },
   "cell_type": "code",
   "source": "# retrieval_chain(query, retriever, llm_openai)",
   "id": "29456b79729475cf",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:14.311275Z",
     "start_time": "2025-04-11T13:30:14.299756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel,Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class RouteQuery(BaseModel):\n",
    "    datasource: Literal[\"vector_store_contact_information\",\n",
    "        \"vector_store_education\",\n",
    "        \"vector_store_experience\",\n",
    "        \"vector_store_technical_skills\",\n",
    "        \"vector_store_projects\",\n",
    "        \"vector_store_clubs_and_community\",\n",
    "        \"vector_store_achievements\",\n",
    "        \"vector_store_publications\",] = Field(\n",
    "        ..., description=\"Given a user question choose which datasource would be most relevant for answering their question\"\n",
    "    )"
   ],
   "id": "92bb1baf2bd3f",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:14.342322Z",
     "start_time": "2025-04-11T13:30:14.314274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "structured_llm = llm_openai.with_structured_output(RouteQuery)\n",
    "system = \"\"\"You are an expert at routing a user question to the appropriate data source.\n",
    "Based on the programming language the question is referring to, route it to the relevant datasources\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "[    (\"system\", system),\n",
    "    (\"human\", \"{question}\"),\n",
    "]\n",
    ")\n",
    "\n",
    "router = prompt | structured_llm"
   ],
   "id": "933df675d77736c7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sreec\\anaconda3\\envs\\HR_METADATA\\lib\\site-packages\\langchain_openai\\chat_models\\base.py:1377: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n",
      "C:\\Users\\sreec\\anaconda3\\envs\\HR_METADATA\\lib\\site-packages\\langchain_openai\\chat_models\\base.py:1390: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo-0125 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:14.357842Z",
     "start_time": "2025-04-11T13:30:14.345321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def route_subqueries(subqueries_list):\n",
    "    result = {}\n",
    "    for i in subqueries_list:\n",
    "        data_source = router.invoke(i)\n",
    "        result[i] = data_source\n",
    "    return result "
   ],
   "id": "8a7500561822393f",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:15.220175Z",
     "start_time": "2025-04-11T13:30:14.361842Z"
    }
   },
   "cell_type": "code",
   "source": "routing_mapping = route_subqueries(list_of_sub_queries)",
   "id": "d8c9aa1b5e93dbc6",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:15.314178Z",
     "start_time": "2025-04-11T13:30:15.248027Z"
    }
   },
   "cell_type": "code",
   "source": "routing_mapping",
   "id": "f7bc21ef275e40e1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Looking for someone with previous experience in Game Development or Graphic designing Specific years of experience may vary based on seniority.': RouteQuery(datasource='vector_store_experience')}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:15.344739Z",
     "start_time": "2025-04-11T13:30:15.321707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mappings_vector_stores = {\"vector_store_contact_information\":vector_store_contact_information,\n",
    " \"vector_store_education\":vector_store_education,\n",
    " \"vector_store_experience\":vector_store_experience,\n",
    " \"vector_store_technical_skills\":vector_store_technical_skills,\n",
    " \"vector_store_projects\":vector_store_projects,\n",
    " \"vector_store_clubs_and_community\":vector_store_clubs_and_communities,\n",
    " \"vector_store_achievements\":vector_store_achievements,\n",
    " \"vector_store_publications\":vector_store_publications}"
   ],
   "id": "ae2a8e971428fcae",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:15.453447Z",
     "start_time": "2025-04-11T13:30:15.408245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def retrieve_information_from_multiple_vector_stores(routing_map):\n",
    "    for question, route in routing_map:\n",
    "        retriever = mappings_vector_stores[route.datasource]\n",
    "        query_1 = question\n",
    "        result = retriever.invoke({\"question\": query_1})\n",
    "        print(result)"
   ],
   "id": "b2f4d90039d76bf3",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:15.515545Z",
     "start_time": "2025-04-11T13:30:15.490492Z"
    }
   },
   "cell_type": "code",
   "source": "routing_mapping = dict(routing_mapping)",
   "id": "5c63f4d0f6cfbb68",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:15.608977Z",
     "start_time": "2025-04-11T13:30:15.522068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "reasoning_prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"\n",
    "You are an intelligent assistant evaluating candidate profiles against job requirements.\n",
    "\n",
    "Below are the subqueries that specify the hiring needs:\n",
    "{subqueries}\n",
    "\n",
    "Here are the retrieved candidate profiles:\n",
    "{context}\n",
    "\n",
    "Instructions:\n",
    "- For each subquery, identify its **core requirement**.\n",
    "- Evaluate each candidate profile **against every subquery**, checking each requirement one-by-one.\n",
    "- A candidate must **satisfy all subqueries** (logical AND) to be included.\n",
    "- Use **only explicit facts** from the profile text. No assumptions.\n",
    "- For each candidate, justify inclusion by showing how they satisfy *every subquery*.\n",
    "\n",
    "Return the final result as a JSON object in this format:\n",
    "{{{{ \n",
    "  \"matching_candidates\": [\n",
    "    {{{{ \n",
    "      \"identifier\": \"...\",   // email, ID, or unique field\n",
    "      \"reason\": \"Matched all requirements: (1) ..., (2) ..., etc.\"\n",
    "    }}}}\n",
    "  ]\n",
    "}}}}\n",
    "\n",
    "Begin evaluation now.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# \n",
    "# Reasoning Agent\n",
    "def reasoning_agent(subqueries, docs, llm):\n",
    "    subquery_text = \"\\n\".join([f\"- {sq}\" for sq in subqueries])\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    chain = reasoning_prompt | llm | StrOutputParser()\n",
    "    print(subquery_text)\n",
    "    print(context)\n",
    "    return chain.invoke({\n",
    "        \"subqueries\": subquery_text,\n",
    "        \"context\": context\n",
    "    })\n",
    "\n",
    "import concurrent.futures\n",
    "def retrieve_documents_parallel(subquery, route, vector_store_map):\n",
    "    datasource = route.datasource\n",
    "    vectorstore = vector_store_map.get(datasource)\n",
    "    \n",
    "    if not vectorstore:\n",
    "        print(f\"[⚠️ Warning] No vector store found for: {datasource}\")\n",
    "        return [], subquery\n",
    "\n",
    "    retriever = vectorstore.as_retriever(search_type=\"similarity\")\n",
    "    docs = retriever.get_relevant_documents(subquery)\n",
    "    return docs, subquery\n",
    "\n",
    "def multi_retrieval_chain(routing_mapping, vector_store_map, llm):\n",
    "    all_docs = []\n",
    "    subqueries = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(retrieve_documents_parallel, subquery, route, vector_store_map)\n",
    "            for subquery, route in routing_mapping.items()\n",
    "        ]\n",
    "\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            docs, subquery = future.result()\n",
    "            all_docs.extend(docs)\n",
    "            subqueries.append(subquery)\n",
    "\n",
    "    return reasoning_agent(subqueries, all_docs, llm)"
   ],
   "id": "eed3a2fb13f98c0c",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:20.477368Z",
     "start_time": "2025-04-11T13:30:15.625502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "vector_store_map = mappings_vector_stores\n",
    "llm = llm\n",
    "final_output = multi_retrieval_chain(routing_mapping, vector_store_map, llm)\n",
    "final_output"
   ],
   "id": "eda9d949d381b252",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sreec\\AppData\\Local\\Temp\\ipykernel_46852\\3667425332.py:58: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(subquery)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Looking for someone with previous experience in Game Development or Graphic designing Specific years of experience may vary based on seniority.\n",
      "nevillejs24@gmail.com[{'company': 'BOSCH', 'position': 'Project Intern - .NET Framework', 'duration': 'April 2024 - Present', 'location': 'Bangalore, India', 'responsibilities': ['Designed and built configurable data visualization tools for RPS data analysis, enabling parameter adjustments for better insights.', 'Implemented a binary ARIMA model from scratch in C# to forecast events using binary time series modeling.', 'Designed the software for easy integration with existing systems, with rigorous testing underway to ensure reliability and performance.']}, {'company': 'PESU I/O', 'position': 'Subject Matter Expert', 'duration': 'October 2024 - November 2024', 'location': 'Bangalore, India', 'responsibilities': ['Designed and taught a game development course where students built a basic game engine from scratch using WebGL for rendering, implementing key game mechanics, graphics, and rendering techniques.', 'Delivered a comprehensive course on graphics programming with WebGL, covering shader programming, rendering techniques, and various graphics concepts.']}, {'company': 'Destination Designs', 'position': 'Project Intern - Next.js, React, MongoDB, Node.js, AWS', 'duration': 'September 2023 - January 2024', 'location': 'Bangalore, India', 'responsibilities': ['Developed an advanced image optimization pipeline that reduced load times, enhanced scalability, and lowered operational costs.', 'Created a dynamic and responsive user interface to display architecture projects using React, and transitioned database utilities from Express to Next.js Serverless functions, boosting performance and scalability.']}]\n",
      "\n",
      "rithul1905@gmail.com[{'company': 'CENTRE OF DATA MODELLING, ANALYTICS AND VISUALIZATION, PESU', 'position': 'RESEARCH INTERN', 'duration': 'Jun 2024 – Aug 2024', 'location': 'Bangalore, Karnataka', 'responsibilities': ['Tasked with developing a high-performance algorithmic trading system for volatile market conditions, focusing on combining traditional time-series analysis with real-time market sentiment data.', 'Led the design and implementation of a novel hybrid neural network architecture integrating Long Short-Term Memory (LSTM) networks with Kolmogorov Arnold Networks (KAN), optimizing for non-linear pattern recognition in financial time series.', 'Engineered an advanced data pipeline integrating vector databases, RAG pipeline, and FinBERT for comprehensive financial data processing, combining OHLC market data with real-time sentiment analysis from over 1000+ financial news articles spanning 30 days and 2 years of historical stock data.', 'Achieved 30% improvement in directional prediction accuracy compared to traditional LSTM models.']}]\n",
      "\n",
      "+919618403578[{'company': 'PES University', 'position': 'Research Intern', 'duration': 'June 2024 - Present', 'location': 'Bangalore, India', 'responsibilities': ['Applicating LLM’s and algorithmic retrieval techniques to find the research gap and finding a suitable model for a dataset.']}]\n",
      "\n",
      "raghav.balakrishnan@gmail.com[{'company': 'Centre of Data Modelling, Analytics and Visualization, PES University', 'position': 'Research Intern', 'duration': 'Jun 2024 – Aug 2024', 'location': 'Bangalore, India', 'responsibilities': ['Engineered an advanced hybrid neural network model by combining Long Short-Term Memory (LSTM) networks with Kolmogorov Arnold Networks (KAN) for stock price forecasting.', 'Designed and implemented a robust data pipeline that integrates text data with numerical OHLC data to enhance predictive accuracy.', 'Developed and fine-tuned the hybrid model for algorithmic trading applications, resulting in improved predictive accuracy and trading strategy performance.']}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, so I need to evaluate these candidate profiles against the job requirements. The main requirement is that the candidate should have previous experience in either Game Development or Graphic Design. The years of experience can vary based on seniority, but the key is that they must have some relevant experience in those areas.\\n\\nLet me go through each candidate one by one.\\n\\nFirst, nevillejs24@gmail.com. Looking at their profile, they have three different roles. At BOSCH, they were a Project Intern working with .NET Framework. Their responsibilities included designing data visualization tools and implementing a binary ARIMA model. That seems more on the data analysis and software development side, not directly related to game development or graphic design.\\n\\nThen, they were a Subject Matter Expert at PESU I/O. There, they designed and taught a game development course where students built a basic game engine using WebGL. They also taught graphics programming with WebGL, covering shaders and rendering techniques. This definitely falls under game development and graphic design. So that\\'s a strong point.\\n\\nAt Destination Designs, they worked as a Project Intern with Next.js, React, etc. They developed an image optimization pipeline and created a responsive UI. While this involves some graphic elements, it\\'s more about web development and optimization, not specifically game development or graphic design in the traditional sense.\\n\\nSo, nevillejs24@gmail.com has experience in game development and graphic design through their role at PESU I/O. That satisfies the core requirement.\\n\\nNext, rithul1905@gmail.com. They were a Research Intern at the Centre of Data Modelling, Analytics, and Visualization. Their responsibilities involved developing an algorithmic trading system, designing a hybrid neural network, and engineering a data pipeline. This is more about data science, machine learning, and financial analysis. There\\'s no mention of game development or graphic design here. So, they don\\'t meet the requirement.\\n\\nThen, +919618403578. They were a Research Intern at PES University. Their main responsibility was applying LLMs and algorithmic retrieval techniques for research. Again, this is more about data analysis and research methods, not game development or graphic design. So, they don\\'t fit.\\n\\nLastly, raghav.balakrishnan@gmail.com. He was a Research Intern at the Centre of Data Modelling, Analytics, and Visualization. His work involved engineering a hybrid neural network for stock price forecasting and designing a data pipeline. This is again in the realm of data science and machine learning, not related to game development or graphic design. So, he doesn\\'t meet the requirement either.\\n\\nSo, out of all the candidates, only nevillejs24@gmail.com has the necessary experience in game development and graphic design. The others are more focused on data science, machine learning, and software development, which don\\'t align with the job requirements specified.\\n</think>\\n\\n```json\\n{\\n  \"matching_candidates\": [\\n    {\\n      \"identifier\": \"nevillejs24@gmail.com\",\\n      \"reason\": \"Matched all requirements: (1) Previous experience in Game Development as evidenced by designing and teaching a game development course and implementing key game mechanics. (2) Previous experience in Graphic Design as evidenced by teaching graphics programming with WebGL and shader programming.\"\\n    }\\n  ]\\n}\\n```'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:20.585423Z",
     "start_time": "2025-04-11T13:30:20.545386Z"
    }
   },
   "cell_type": "code",
   "source": "print(final_output)",
   "id": "f667b22398f11113",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to evaluate these candidate profiles against the job requirements. The main requirement is that the candidate should have previous experience in either Game Development or Graphic Design. The years of experience can vary based on seniority, but the key is that they must have some relevant experience in those areas.\n",
      "\n",
      "Let me go through each candidate one by one.\n",
      "\n",
      "First, nevillejs24@gmail.com. Looking at their profile, they have three different roles. At BOSCH, they were a Project Intern working with .NET Framework. Their responsibilities included designing data visualization tools and implementing a binary ARIMA model. That seems more on the data analysis and software development side, not directly related to game development or graphic design.\n",
      "\n",
      "Then, they were a Subject Matter Expert at PESU I/O. There, they designed and taught a game development course where students built a basic game engine using WebGL. They also taught graphics programming with WebGL, covering shaders and rendering techniques. This definitely falls under game development and graphic design. So that's a strong point.\n",
      "\n",
      "At Destination Designs, they worked as a Project Intern with Next.js, React, etc. They developed an image optimization pipeline and created a responsive UI. While this involves some graphic elements, it's more about web development and optimization, not specifically game development or graphic design in the traditional sense.\n",
      "\n",
      "So, nevillejs24@gmail.com has experience in game development and graphic design through their role at PESU I/O. That satisfies the core requirement.\n",
      "\n",
      "Next, rithul1905@gmail.com. They were a Research Intern at the Centre of Data Modelling, Analytics, and Visualization. Their responsibilities involved developing an algorithmic trading system, designing a hybrid neural network, and engineering a data pipeline. This is more about data science, machine learning, and financial analysis. There's no mention of game development or graphic design here. So, they don't meet the requirement.\n",
      "\n",
      "Then, +919618403578. They were a Research Intern at PES University. Their main responsibility was applying LLMs and algorithmic retrieval techniques for research. Again, this is more about data analysis and research methods, not game development or graphic design. So, they don't fit.\n",
      "\n",
      "Lastly, raghav.balakrishnan@gmail.com. He was a Research Intern at the Centre of Data Modelling, Analytics, and Visualization. His work involved engineering a hybrid neural network for stock price forecasting and designing a data pipeline. This is again in the realm of data science and machine learning, not related to game development or graphic design. So, he doesn't meet the requirement either.\n",
      "\n",
      "So, out of all the candidates, only nevillejs24@gmail.com has the necessary experience in game development and graphic design. The others are more focused on data science, machine learning, and software development, which don't align with the job requirements specified.\n",
      "</think>\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"matching_candidates\": [\n",
      "    {\n",
      "      \"identifier\": \"nevillejs24@gmail.com\",\n",
      "      \"reason\": \"Matched all requirements: (1) Previous experience in Game Development as evidenced by designing and teaching a game development course and implementing key game mechanics. (2) Previous experience in Graphic Design as evidenced by teaching graphics programming with WebGL and shader programming.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:20.648564Z",
     "start_time": "2025-04-11T13:30:20.614952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from dataclasses import dataclass\n",
    "# from datetime import datetime, timedelta\n",
    "# import smtplib\n",
    "# from email.mime.multipart import MIMEMultipart\n",
    "# from email.mime.text import MIMEText\n",
    "# import ssl\n",
    "# from pydantic_ai import Agent, Tool\n",
    "# from typing import List\n",
    "# import json\n",
    "# import nest_asyncio\n",
    "# import asyncio\n",
    "# \n",
    "# nest_asyncio.apply()\n",
    "# \n",
    "# @dataclass\n",
    "# class EmailConfig:\n",
    "#     sender_email: str = \"morningnamastelucifer@gmail.com\"\n",
    "#     password: str = \"nnki vnbm gnzp qyvj\"  # Use env vars in production\n",
    "# \n",
    "# @dataclass\n",
    "# class Candidate:\n",
    "#     name: str\n",
    "#     email: str\n",
    "#     position: str\n",
    "#     available_dates: List[str]\n",
    "# \n",
    "# system_prompt = \"\"\"\\\n",
    "# You are an Interview Scheduling Assistant. Your tasks:\n",
    "# 1. Generate personalized interview invitation emails\n",
    "# 2. Propose suitable time slots\n",
    "# 3. Include interview format details\n",
    "# 4. Maintain professional tone\n",
    "# \"\"\"\n",
    "# \n",
    "# def send_email(subject: str, body: str, to_email: str, config: EmailConfig) -> str:\n",
    "#     msg = MIMEMultipart()\n",
    "#     msg['From'] = config.sender_email\n",
    "#     msg['To'] = to_email\n",
    "#     msg['Subject'] = subject\n",
    "#     msg.attach(MIMEText(body, 'plain'))\n",
    "#     \n",
    "#     context = ssl.create_default_context()\n",
    "#     \n",
    "#     try:\n",
    "#         with smtplib.SMTP('smtp.gmail.com', 587) as server:\n",
    "#             server.starttls(context=context)\n",
    "#             server.login(config.sender_email, config.password)\n",
    "#             server.send_message(msg)\n",
    "#         return f\"Email sent to {to_email}\"\n",
    "#     except Exception as e:\n",
    "#         return f\"Error: {str(e)}\"\n",
    "# \n",
    "# def generate_time_slots(start_date: str) -> List[str]:\n",
    "#     slots = []\n",
    "#     current_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "#     \n",
    "#     for _ in range(3):  # Next 3 days\n",
    "#         for hour in [9, 11, 14, 16]:  # 4 slots per day\n",
    "#             slot = current_date.replace(hour=hour, minute=0)\n",
    "#             slots.append(slot.strftime(\"%A, %B %d at %I:%M %p\"))\n",
    "#         current_date += timedelta(days=1)\n",
    "#     \n",
    "#     return slots\n",
    "# \n",
    "# def create_email_content(candidate: Candidate, slots: List[str]) -> dict:\n",
    "#     return {\n",
    "#         \"subject\": f\"Interview for {candidate.position}\",\n",
    "#         \"body\": f\"\"\"Dear {candidate.name},\n",
    "#         \n",
    "# We're excited to interview you for {candidate.position}.\n",
    "# \n",
    "# Available slots:\n",
    "# {chr(10).join(f\"- {s}\" for s in slots[:3])}\n",
    "# \n",
    "# Please reply with your preferred time.\n",
    "# \n",
    "# Best regards,\n",
    "# Hiring Team\n",
    "# \"\"\"\n",
    "#     }\n",
    "# \n",
    "# # Create agent\n",
    "# interview_agent = Agent(\n",
    "#     'gpt-3.5-turbo',\n",
    "#     deps_type=EmailConfig,\n",
    "#     tools=[\n",
    "#         Tool(send_email, takes_ctx=False),\n",
    "#         Tool(generate_time_slots, takes_ctx=False),\n",
    "#         Tool(create_email_content, takes_ctx=False)\n",
    "#     ],\n",
    "#     system_prompt=system_prompt\n",
    "# )\n",
    "# \n",
    "# def schedule_interviews(candidates: List[Candidate], start_date: str):\n",
    "#     \"\"\"Run the scheduling process\"\"\"\n",
    "#     config = EmailConfig()\n",
    "#     \n",
    "#     for candidate in candidates:\n",
    "#         slots = generate_time_slots(start_date)\n",
    "#         email = create_email_content(candidate, slots)\n",
    "#         \n",
    "#         # Prepare context string\n",
    "#         context = json.dumps({\n",
    "#             \"candidate\": candidate.name,\n",
    "#             \"position\": candidate.position,\n",
    "#             \"slots\": slots[:3]\n",
    "#         })\n",
    "#         \n",
    "#         try:\n",
    "#             # Run agent synchronously with loop handling\n",
    "#             result = interview_agent.run_sync(\n",
    "#                 f\"Send interview email with these details: {context}\",\n",
    "#                 deps=config\n",
    "#             )\n",
    "#             print(result.data)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error scheduling {candidate.name}: {str(e)}\")\n",
    "# \n",
    "# if __name__ == '__main__':\n",
    "#     candidates = [\n",
    "#         Candidate(\n",
    "#             name=\"John Doe\",\n",
    "#             email=\"morningnamastelucifer@gmail.com\",\n",
    "#             position=\"Data Scientist\",\n",
    "#             available_dates=[\"2023-12-10\"]\n",
    "#         )\n",
    "#     ]\n",
    "#     \n",
    "#     schedule_interviews(candidates, \"2023-12-10\")"
   ],
   "id": "df6b9600cd002e40",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:20.664088Z",
     "start_time": "2025-04-11T13:30:20.652563Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f71ecf5e6e0ddf4a",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:20.680120Z",
     "start_time": "2025-04-11T13:30:20.668089Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2cb410c9dd165018",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:30:20.695704Z",
     "start_time": "2025-04-11T13:30:20.683132Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b0e362a6d0404f8",
   "outputs": [],
   "execution_count": 65
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
